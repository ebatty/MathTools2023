
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Tutorial 1 &#8212; Mathematical Tools for Neuroscientists</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tutorial 2" href="Week5Tutorial2.html" />
    <link rel="prev" title="Video 5.3: PCA" href="Video53.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Mathematical Tools for Neuroscientists</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Linear Algebra &amp; Dynamical Systems
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week1/Overview.html">
   Week 1: Vectors
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Video11.html">
     Video 1.1: What is a vector?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Video12.html">
     Video 1.2: Vector properties &amp; operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Video13.html">
     Video 1.3: Vector spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Week1Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Week1Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week2/Overview.html">
   Week 2: Matrices
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video21.html">
     Video 2.1: Linear transformations and matrices (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video22.html">
     Video 2.2: Matrix multiplication as composition(3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video23.html">
     Video 2.3: The determinant (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video24.html">
     Video 2.4: Inverse matrices, column space, and null space (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video25.html">
     Video 2.5: Nonsquare matrices as transformations between dimensions (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Week2Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Week2Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week3/Overview.html">
   Week 3: Discrete Dynamics &amp; Eigenstuff
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Video31.html">
     Video 3.1: Intro to Dynamical Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Video32.html">
     Video 3.2: Discrete Dynamical Neural Circuit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Video33.html">
     Video 3.3: Eigenvalues and eigenvectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Week3Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Week3Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week4/Overview.html">
   Week 4: Continuous Dynamical Systems &amp; Differential Equations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/KeyConcepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video41.html">
     Video 4.1: Eigenvalues &amp; Discrete Dynamical Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video42.html">
     Video 4.2: Review of Differentiation &amp; Integration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video43.html">
     Video 4.3: Solving differential equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video44.html">
     Video 4.4: Systems of differential equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Week4Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Week4Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="Overview.html">
   Week 5: Matrix Decomposition &amp; Dimensionality Reduction
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="Video51.html">
     Video 5.1: Special Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Video52.html">
     Video 5.2: Matrix Decomposition &amp; SVD
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Video53.html">
     Video 5.3: PCA
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week5Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../LinearAlgebraReview/Overview.html">
   Review
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../LinearAlgebraReview/MathTools_Homework1.html">
     Homework 1
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probability &amp; Statistics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week6/Overview.html">
   Week 6: Intro to Probability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week6/KeyConcepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week6/Reading61.html">
     Reading 6.1: Intro to Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week6/Week6Tutorial1.html">
     Tutorial 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week7/Overview.html">
   Week 7: Intro to Statistics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video71.html">
     Video 7.1: Descriptive Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video72.html">
     Video 7.2: Overview of Statistical Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video73.html">
     Video 7.3: Point Estimators Examples &amp; Goodness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video74.html">
     Video 7.4: Maximum Likelihood Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video75.html">
     Video 7.5: Bayesian Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Week7Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Week7Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week8/Overview.html">
   Week 8: Statistical Encoding &amp; Decoding
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week8/Video81.html">
     Video 8.1: What are encoding &amp; decoding?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week8/Video82.html">
     Video 8.2: Statistical encoding models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week8/Week8Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week8/Week8Tutorial2.html">
     (Optional) Tutorial 2
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week9/Overview.html">
   Week 9: Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Video91.html">
     Video 9.1: What is machine learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Video92.html">
     Video 9.2: Types of machine learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Video93.html">
     Video 9.3: Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Week9Tutorial1.html">
     Tutorial 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week10/Overview.html">
   Week 10: Model Selection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/Video101.html">
     Video 10.1: Model evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/Video102.html">
     Video 10.2: Bootstrapping (NMA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/Video103.html">
     Video 10.3: Model selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/Week10Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/Week10Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week11/Overview.html">
   Week 11: Clustering &amp; Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Video111.html">
     Video 11.1: Clustering Applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Video112.html">
     Video 11.2: Types of Clustering Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Video113.html">
     Video 11.3: K-Means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Week11Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Week11Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week12/Overview.html">
   Week 12: Deep Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video121.html">
     Video 12.1: Feedforward networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video122.html">
     Video 12.2: Training Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video123.html">
     Video 12.3: Practical steps for training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video124.html">
     Reaching 12.4: Intro to Pytorch
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://colab.research.google.com/github/ebatty/MathToolsforNeuroscience/blob/jupyterbook/Week5/Week5Tutorial1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/Week5/Week5Tutorial1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#key-concept-review-coding-tips">
   Key concept review &amp; coding tips
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#special-matrices">
     Special matrices
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#diagonal-matrices">
       Diagonal matrices
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#orthogonal-matrices">
       Orthogonal matrices
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#symmetric-matrices">
       Symmetric matrices
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matrix-decomposition">
     Matrix decomposition
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#eigendecomposition">
       Eigendecomposition
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#singular-value-decomposition">
       Singular value decomposition
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dimensionality-reduction">
     Dimensionality Reduction
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#principal-components-analysis">
       Principal components analysis
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-1-delving-into-svd">
   Exercise 1: Delving into SVD
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-computing-the-svd">
     A) Computing the SVD
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-svd-step-by-step-transformations">
     B) SVD step by step transformations
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-c-low-rank-approximation">
     (Optional) C) Low rank approximation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-extra-info-orthogonal-matrices-can-also-reflect">
     (Optional) Extra info: Orthogonal matrices can also reflect
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-2-pca-implementation-and-correlation-exploration">
   Exercise 2: PCA implementation and correlation exploration
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modified-from-nma-w1d5-t2">
     Modified from NMA W1D5 T2
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-interactive-demo-identifying-first-principal-component">
     A) Interactive Demo: Identifying first principal component
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-implement-pca">
     B) Implement PCA
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#c-visualize-variance-explained">
     C) Visualize variance explained
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#d-interactive-demo-exploration-of-the-correlation-coefficient">
     D) Interactive Demo: Exploration of the correlation coefficient
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-advanced-challenge-pca-implementation-with-svd">
     Optional advanced challenge: PCA implementation with SVD
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-3-pca-of-images">
   Exercise 3: PCA of images
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modified-from-nma-w1d5-t3">
     Modified from NMA W1D5 T3
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-explained-variances">
     A) Explained variances
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-pca-reconstruction">
     B) PCA Reconstruction
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#c-interactive-demo-reconstruct-the-data-matrix-using-different-numbers-of-pcs">
     C) Interactive Demo: Reconstruct the data matrix using different numbers of PCs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#d-visualization-of-the-principal-components">
     D) Visualization of the principal components
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-only-e-denoising-with-pca">
     (Read only) E) Denoising with PCA
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extra-info-pca-sklearn">
   Extra info: PCA &amp; Sklearn
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Tutorial 1</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#key-concept-review-coding-tips">
   Key concept review &amp; coding tips
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#special-matrices">
     Special matrices
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#diagonal-matrices">
       Diagonal matrices
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#orthogonal-matrices">
       Orthogonal matrices
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#symmetric-matrices">
       Symmetric matrices
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matrix-decomposition">
     Matrix decomposition
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#eigendecomposition">
       Eigendecomposition
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#singular-value-decomposition">
       Singular value decomposition
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dimensionality-reduction">
     Dimensionality Reduction
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#principal-components-analysis">
       Principal components analysis
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-1-delving-into-svd">
   Exercise 1: Delving into SVD
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-computing-the-svd">
     A) Computing the SVD
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-svd-step-by-step-transformations">
     B) SVD step by step transformations
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-c-low-rank-approximation">
     (Optional) C) Low rank approximation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-extra-info-orthogonal-matrices-can-also-reflect">
     (Optional) Extra info: Orthogonal matrices can also reflect
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-2-pca-implementation-and-correlation-exploration">
   Exercise 2: PCA implementation and correlation exploration
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modified-from-nma-w1d5-t2">
     Modified from NMA W1D5 T2
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-interactive-demo-identifying-first-principal-component">
     A) Interactive Demo: Identifying first principal component
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-implement-pca">
     B) Implement PCA
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#c-visualize-variance-explained">
     C) Visualize variance explained
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#d-interactive-demo-exploration-of-the-correlation-coefficient">
     D) Interactive Demo: Exploration of the correlation coefficient
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-advanced-challenge-pca-implementation-with-svd">
     Optional advanced challenge: PCA implementation with SVD
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-3-pca-of-images">
   Exercise 3: PCA of images
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modified-from-nma-w1d5-t3">
     Modified from NMA W1D5 T3
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-explained-variances">
     A) Explained variances
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-pca-reconstruction">
     B) PCA Reconstruction
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#c-interactive-demo-reconstruct-the-data-matrix-using-different-numbers-of-pcs">
     C) Interactive Demo: Reconstruct the data matrix using different numbers of PCs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#d-visualization-of-the-principal-components">
     D) Visualization of the principal components
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-only-e-denoising-with-pca">
     (Read only) E) Denoising with PCA
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extra-info-pca-sklearn">
   Extra info: PCA &amp; Sklearn
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p><a href="https://colab.research.google.com/github/ebatty/MathToolsforNeuroscience/blob/jupyterbook/Week5/Week5Tutorial1.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-1">
<h1>Tutorial 1<a class="headerlink" href="#tutorial-1" title="Permalink to this headline">#</a></h1>
<p><strong>Linear Algebra IV: Matrix Decomposition &amp; Dimensionality Reduction</strong></p>
<p><strong>[insert your name]</strong></p>
<p><strong>Important reminders</strong>: Before starting, click “File -&gt; Save a copy in Drive”. Produce a pdf for submission by “File -&gt; Print” and then choose “Save to PDF”.</p>
<p>To complete this tutorial, you should have watched Videos 4.1, 4.2, 4.3, and 4.4.</p>
<p><strong>Credits</strong>: Video 4.3 is the Week 1 Day 5 Intro Video from NMA (Neuromatch Academy) (https://github.com/NeuromatchAcademy/course-content). Exercise 2/3 in this tutorial are modified from content in NMA W1D5 tutorials.</p>
<p>We are again using code for visualizing linear transformations from https://openedx.seas.gwu.edu/courses/course-v1:GW+EngComp4+2019/about. In particular, we are using their <code class="docutils literal notranslate"><span class="pre">plot_linear_transformation</span></code> and <code class="docutils literal notranslate"><span class="pre">plot_linear_transformations</span></code> functions.</p>
<p>The interactive demo in Exercise 2A is based on matlab code from: https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues</p>
<p>Imports</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Imports

# Imports
import numpy as np
import matplotlib.pyplot as plt
import ipywidgets as widgets  # interactive display
</pre></div>
</div>
</div>
</div>
<p>Plotting functions</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Plotting functions
import numpy
from numpy.linalg import inv, eig
from math import ceil
from matplotlib import pyplot, ticker, get_backend, rc
from mpl_toolkits.mplot3d import Axes3D
from itertools import cycle


%config InlineBackend.figure_format = &#39;retina&#39;
plt.style.use(&quot;https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle&quot;)

classic = &#39;k&#39;

_int_backends = [&#39;GTK3Agg&#39;, &#39;GTK3Cairo&#39;, &#39;MacOSX&#39;, &#39;nbAgg&#39;,
                 &#39;Qt4Agg&#39;, &#39;Qt4Cairo&#39;, &#39;Qt5Agg&#39;, &#39;Qt5Cairo&#39;,
                 &#39;TkAgg&#39;, &#39;TkCairo&#39;, &#39;WebAgg&#39;, &#39;WX&#39;, &#39;WXAgg&#39;, &#39;WXCairo&#39;]
_backend = get_backend()   # get current backend name

# shrink figsize and fontsize when using %matplotlib notebook
if _backend in _int_backends:
    fontsize = 4
    fig_scale = 0.75
else:
    fontsize = 5
    fig_scale = 1

grey = &#39;#808080&#39;
gold = &#39;#cab18c&#39;   # x-axis grid
lightblue = &#39;#0096d6&#39;  # y-axis grid
green = &#39;#008367&#39;  # x-axis basis vector
red = &#39;#E31937&#39;    # y-axis basis vector
darkblue = &#39;#004065&#39;

pink, yellow, orange, purple, brown = &#39;#ef7b9d&#39;, &#39;#fbd349&#39;, &#39;#ffa500&#39;, &#39;#a35cff&#39;, &#39;#731d1d&#39;

quiver_params = {&#39;angles&#39;: &#39;xy&#39;,
                 &#39;scale_units&#39;: &#39;xy&#39;,
                 &#39;scale&#39;: 1,
                 &#39;width&#39;: 0.012}

grid_params = {&#39;linewidth&#39;: 0.5,
               &#39;alpha&#39;: 0.8}
def plot_sample_images(X):
  &quot;&quot;&quot;
  Plots 9 images from the data.

  Args:
     X (numpy array of floats) : Data matrix each column corresponds to a
                                 different random variable

  Returns:
    Nothing.

  &quot;&quot;&quot;
  im_size = int(np.sqrt(X.shape[1]))
  fig, ax = plt.subplots()
  k = 0
  for k1 in range(3):
    for k2 in range(3):
      k = k + 1
      plt.imshow(np.reshape(X[k, :], (im_size, im_size)),
                 extent=[(k1 + 1) * im_size, k1 * im_size, (k2+1) * im_size, k2 * im_size],
                 vmin=0, vmax=255, cmap=&#39;gray&#39;)
  plt.xlim((3 * im_size, 0))
  plt.ylim((3 * im_size, 0))
  plt.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, bottom=False, top=False,
                  labelbottom=False)
  plt.clim([0, 250])
  ax.set_xticks([])
  ax.set_yticks([])
  plt.show()


def plot_variance_explained(variance_explained):
  &quot;&quot;&quot;
  Plots eigenvalues.

  Args:
    variance_explained (numpy array of floats) : Vector of variance explained
                                                 for each PC

  Returns:
    Nothing.

  &quot;&quot;&quot;

  plt.figure()
  plt.plot(np.arange(1, len(variance_explained) + 1), variance_explained,
           &#39;--k&#39;)
  plt.xlabel(&#39;Number of components&#39;)
  plt.ylabel(&#39;Variance explained&#39;)
  plt.show()

def plot_reconstructions(X, X_reconstructed):
  &quot;&quot;&quot;
  Plots 9 images in the dataset side-by-side with the reconstructed
  images.

  Args:
    X (numpy array of floats)               : Data matrix each column
                                              corresponds to a different
                                              random variable
    X_reconstructed (numpy array of floats) : Data matrix each column
                                              corresponds to a different
                                              random variable

  Returns:
    Nothing.
  &quot;&quot;&quot;

  im_size = int(np.sqrt(X.shape[1]))

  plt.figure()
  ax = plt.subplot(121)
  k = 0
  for k1 in range(3):
    for k2 in range(3):
      k = k + 1
      plt.imshow(np.reshape(X[k, :], (im_size, im_size)),
                 extent=[(k1 + 1) * im_size, k1 * im_size, (k2 + 1) * im_size, k2 * im_size],
                 vmin=0, vmax=255, cmap=&#39;gray&#39;)
  plt.xlim((3 * im_size, 0))
  plt.ylim((3 * im_size, 0))
  plt.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, bottom=False, top=False,
                  labelbottom=False)
  ax.set_xticks([])
  ax.set_yticks([])
  plt.title(&#39;Data&#39;)
  plt.clim([0, 250])
  ax = plt.subplot(122)
  k = 0
  for k1 in range(3):
    for k2 in range(3):
      k = k + 1
      plt.imshow(np.reshape(np.real(X_reconstructed[k, :]), (im_size, im_size)),
                 extent=[(k1 + 1) * im_size, k1 * im_size, (k2 + 1) * im_size, k2 * im_size],
                 vmin=0, vmax=255, cmap=&#39;gray&#39;)
  plt.xlim((3 * im_size, 0))
  plt.ylim((3 * im_size, 0))
  plt.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, bottom=False, top=False,
                  labelbottom=False)
  ax.set_xticks([])
  ax.set_yticks([])
  plt.clim([0, 250])
  plt.title(&#39;Reconstructed&#39;)
  plt.tight_layout()

def plot_principal_components(weights):
  &quot;&quot;&quot;
  Visualize PCA basis vector weights. Red = positive weights,
  blue = negative weights, white = zero weight.

  Args:
     weights (numpy array of floats) : PCA basis vector

  Returns:
     Nothing.
  &quot;&quot;&quot;
  im_size = int(np.sqrt(X.shape[1]))

  fig, ax = plt.subplots()
  cmap = plt.cm.get_cmap(&#39;seismic&#39;)
  plt.imshow(np.real(np.reshape(weights, (im_size, im_size))), cmap=cmap)
  plt.tick_params(axis=&#39;both&#39;, which=&#39;both&#39;, bottom=False, top=False,
                  labelbottom=False)
  plt.clim(-.15, .15)
  plt.colorbar(ticks=[-.15, -.1, -.05, 0, .05, .1, .15])
  ax.set_xticks([])
  ax.set_yticks([])
  plt.show()


def plot_pca_transformation(data, transformed_data):


    fig, axes = plt.subplots(1, 2)
    axes[0].scatter(data[:,0], data[:, 1], s=1, c=&#39;#63BA79&#39;);
    for j in range(2):
      axes[j].spines[&#39;right&#39;].set_visible(False)
      axes[j].spines[&#39;top&#39;].set_visible(False)

    orig_correlation = round(np.corrcoef(data[:, 0], data[:, 1])[0, 1], 2)
    axes[0].set(title=&#39;Data in original coordinates \n Correlation = &#39; + str(orig_correlation), xlabel=&#39;Neuron 1 activity&#39;, ylabel=&#39;Neuron 2 activity&#39;, xlim=[-5, 15], ylim=[-5, 15]);

    axes[1].scatter(transformed_data[:,0], transformed_data[:, 1], s=1, c=&#39;#63BA79&#39;);
    pca_correlation = round(np.corrcoef(transformed_data[:, 0], transformed_data[:, 1])[0, 1], 2)
    axes[1].set(title=&#39;Data in PC coordinates  \n Correlation = &#39; + str(pca_correlation), xlabel=&#39;PC 1&#39;, ylabel=&#39;PC 2&#39;);

    plt.tight_layout()

def plot_data_and_PCs(X, W):
  &quot;&quot;&quot;
  Plots bivariate data as well as new basis vectors.

  Args:
    X (numpy array of floats) : Data matrix each column corresponds to a
                                different random variable
    W (numpy array of floats) : Square matrix representing new orthonormal
                                basis each column represents a basis vector

  Returns:
    Nothing.
  &quot;&quot;&quot;

  plt.figure()
  plt.scatter(X[:, 0], X[:, 1], s=1, color=&#39;#63BA79&#39;)
  plt.axis(&#39;equal&#39;)
  plt.xlabel(&#39;Neuron 1 activity&#39;)
  plt.ylabel(&#39;Neuron 2 activity&#39;)
  colors = plt.rcParams[&#39;axes.prop_cycle&#39;].by_key()[&#39;color&#39;]
  plt.plot([0, W[0, 0]], [0, W[1, 0]], color=colors[4], linewidth=1,
           label=&#39;Component 1&#39;)
  plt.plot([0, W[0, 1]], [0, W[1, 1]], color=colors[3], linewidth=1,
           label=&#39;Component 2&#39;)
  plt.legend()
  plt.show()


def plot_vector(vectors, tails=None):
    &#39;&#39;&#39; Draw 2d vectors based on the values of the vectors and the position of their tails.
    
    Parameters
    ----------
    vectors : list.
        List of 2-element array-like structures, each represents a 2d vector.
    
    tails : list, optional.
        List of 2-element array-like structures, each represents the coordinates of the tail
        of the corresponding vector in vectors. If None (default), all tails are set at the
        origin (0,0). If len(tails) is 1, all tails are set at the same position. Otherwise,
        vectors and tails must have the same length.
    
    Examples
    --------
    &gt;&gt;&gt; v = [(1, 3), (3, 3), (4, 6)]
    &gt;&gt;&gt; plot_vector(v)      # draw 3 vectors with their tails at origin
    &gt;&gt;&gt; t = [numpy.array((2, 2))]
    &gt;&gt;&gt; plot_vector(v, t)   # draw 3 vectors with their tails at (2,2)
    &gt;&gt;&gt; t = [[3, 2], [-1, -2], [3, 5]]
    &gt;&gt;&gt; plot_vector(v, t)   # draw 3 vectors with 3 different tails

    &#39;&#39;&#39;   
    vectors = numpy.array(vectors)
    assert vectors.shape[1] == 2, &quot;Each vector should have 2 elements.&quot;  
    if tails is not None:
        tails = numpy.array(tails)
        assert tails.shape[1] == 2, &quot;Each tail should have 2 elements.&quot;
    else:
        tails = numpy.zeros_like(vectors)
    
    # tile vectors or tails array if needed
    nvectors = vectors.shape[0]
    ntails = tails.shape[0]
    if nvectors == 1 and ntails &gt; 1:
        vectors = numpy.tile(vectors, (ntails, 1))
    elif ntails == 1 and nvectors &gt; 1:
        tails = numpy.tile(tails, (nvectors, 1))
    else:
        assert tails.shape == vectors.shape, &quot;vectors and tail must have a same shape&quot;

    # calculate xlimit &amp; ylimit
    heads = tails + vectors
    limit = numpy.max(numpy.abs(numpy.hstack((tails, heads))))
    limit = numpy.ceil(limit * 1.2)   # add some margins
    
    figsize = numpy.array([2,2]) * fig_scale
    figure, axis = pyplot.subplots(figsize=figsize)
    axis.quiver(tails[:,0], tails[:,1], vectors[:,0], vectors[:,1], color=darkblue, 
                  angles=&#39;xy&#39;, scale_units=&#39;xy&#39;, scale=1)
    axis.set_xlim([-limit, limit])
    axis.set_ylim([-limit, limit])
    axis.set_aspect(&#39;equal&#39;)

    # if xticks and yticks of grid do not match, choose the finer one
    xticks = axis.get_xticks()
    yticks = axis.get_yticks()
    dx = xticks[1] - xticks[0]
    dy = yticks[1] - yticks[0]
    base = max(int(min(dx, dy)), 1)   # grid interval is always an integer
    loc = ticker.MultipleLocator(base=base)
    axis.xaxis.set_major_locator(loc)
    axis.yaxis.set_major_locator(loc)
    axis.grid(True, **grid_params)
    
    # show x-y axis in the center, hide frames
    axis.spines[&#39;left&#39;].set_position(&#39;center&#39;)
    axis.spines[&#39;bottom&#39;].set_position(&#39;center&#39;)
    axis.spines[&#39;right&#39;].set_color(&#39;none&#39;)
    axis.spines[&#39;top&#39;].set_color(&#39;none&#39;)

def plot_transformation_helper(axis, matrix, *vectors, unit_vector=True, unit_circle=False, title=None):
    &quot;&quot;&quot; A helper function to plot the linear transformation defined by a 2x2 matrix.
    
    Parameters
    ----------
    axis : class matplotlib.axes.Axes.
        The axes to plot on.

    matrix : class numpy.ndarray.
        The 2x2 matrix to visualize.

    *vectors : class numpy.ndarray.
        The vector(s) to plot along with the linear transformation. Each array denotes a vector&#39;s
        coordinates before the transformation and must have a shape of (2,). Accept any number of vectors. 
    
    unit_vector : bool, optional.
        Whether to plot unit vectors of the standard basis, default to True.
    
    unit_circle: bool, optional.
        Whether to plot unit circle, default to False.
    
    title: str, optional.
        Title of the plot.

    &quot;&quot;&quot;
    assert matrix.shape == (2,2), &quot;the input matrix must have a shape of (2,2)&quot;
    grid_range = 20
    x = numpy.arange(-grid_range, grid_range+1)
    X_, Y_ = numpy.meshgrid(x,x)
    I = matrix[:,0]
    J = matrix[:,1]
    X = I[0]*X_ + J[0]*Y_
    Y = I[1]*X_ + J[1]*Y_
    origin = numpy.zeros(1)
        
    # draw grid lines
    for i in range(x.size):
        axis.plot(X[i,:], Y[i,:], c=gold, **grid_params)
        axis.plot(X[:,i], Y[:,i], c=lightblue, **grid_params)
    
    # draw (transformed) unit vectors
    if unit_vector:
        axis.quiver(origin, origin, [I[0]], [I[1]], color=green, **quiver_params)
        axis.quiver(origin, origin, [J[0]], [J[1]], color=red, **quiver_params)

    # draw optional vectors
    color_cycle = cycle([pink, darkblue, orange, purple, brown])
    if vectors:
        for vector in vectors:
            color = next(color_cycle)
            vector_ = matrix @ vector.reshape(-1,1)
            axis.quiver(origin, origin, [vector_[0]], [vector_[1]], color=color, **quiver_params)

    # draw optional unit circle
    if unit_circle:
        alpha =  numpy.linspace(0, 2*numpy.pi, 41)
        circle = numpy.vstack((numpy.cos(alpha), numpy.sin(alpha)))
        circle_trans = matrix @ circle
        axis.plot(circle_trans[0], circle_trans[1], color=red, lw=0.8)

    # hide frames, set xlimit &amp; ylimit, set title
    limit = 4
    axis.spines[&#39;left&#39;].set_position(&#39;center&#39;)
    axis.spines[&#39;bottom&#39;].set_position(&#39;center&#39;)
    axis.spines[&#39;left&#39;].set_linewidth(0.3)
    axis.spines[&#39;bottom&#39;].set_linewidth(0.3)
    axis.spines[&#39;right&#39;].set_color(&#39;none&#39;)
    axis.spines[&#39;top&#39;].set_color(&#39;none&#39;)
    axis.set_xlim([-limit, limit])
    axis.set_ylim([-limit, limit])
    if title is not None:
        axis.set_title(title)

def plot_linear_transformation(matrix, *vectors, unit_vector=True, unit_circle=False):
    &quot;&quot;&quot; Plot the linear transformation defined by a 2x2 matrix using the helper
    function plot_transformation_helper(). It will create 2 subplots to visualize some
    vectors before and after the transformation.
    
    Parameters
    ----------
    matrix : class numpy.ndarray.
        The 2x2 matrix to visualize.

    *vectors : class numpy.ndarray.
        The vector(s) to plot along with the linear transformation. Each array denotes a vector&#39;s
        coordinates before the transformation and must have a shape of (2,). Accept any number of vectors.
    
    unit_vector : bool, optional.
        Whether to plot unit vectors of the standard basis, default to True.
    
    unit_circle: bool, optional.
        Whether to plot unit circle, default to False.
    
    &quot;&quot;&quot;
    with plt.rc_context({&quot;figure.dpi&quot;: 200, &#39;font.family&#39;:&#39;serif&#39;, &#39;axes.axisbelow&#39;:True, &#39;font.size&#39;:fontsize, &quot;axes.titlesize&quot;:5, &quot;lines.linewidth&quot;:1}):
      figsize = numpy.array([4,2]) * fig_scale
      figure, (axis1, axis2) = pyplot.subplots(1, 2, figsize=figsize)
      plot_transformation_helper(axis1, numpy.identity(2), *vectors, unit_vector=unit_vector, unit_circle=unit_circle, title=&#39;Before transformation&#39;)
      plot_transformation_helper(axis2, matrix, *vectors, unit_vector=unit_vector, unit_circle=unit_circle, title=&#39;After transformation&#39;)

def plot_linear_transformations(*matrices, unit_vector=True, unit_circle=False):
    &quot;&quot;&quot; Plot the linear transformation defined by a sequence of n 2x2 matrices using the helper
    function plot_transformation_helper(). It will create n+1 subplots to visualize some
    vectors before and after each transformation.

    Parameters
    ----------
    *matrices : class numpy.ndarray.
        The 2x2 matrices to visualize. Accept any number of matrices.
    
    unit_vector : bool, optional.
        Whether to plot unit vectors of the standard basis, default to True.
    
    unit_circle: bool, optional.
        Whether to plot unit circle, default to False.
      
    &quot;&quot;&quot;
    nplots = len(matrices) + 1
    nx = 2
    ny = ceil(nplots/nx)
    with plt.rc_context({&quot;figure.dpi&quot;: 200, &#39;font.family&#39;:&#39;serif&#39;, &#39;axes.axisbelow&#39;:True, &#39;font.size&#39;:fontsize, &quot;axes.titlesize&quot;:5, &quot;lines.linewidth&quot;:1}):
      figsize = numpy.array([2*nx, 2*ny]) * fig_scale
      figure, axes = pyplot.subplots(nx, ny, figsize=figsize)

      for i in range(nplots):  # fig_idx 
          if i == 0:
              matrix_trans = numpy.identity(2)
              title = &#39;Before transformation&#39;
          else:
              matrix_trans = matrices[i-1] @ matrix_trans
              if i == 1:
                  title = &#39;After {} transformation&#39;.format(i)
              else:
                  title = &#39;After {} transformations&#39;.format(i)
          plot_transformation_helper(axes[i//nx, i%nx], matrix_trans, unit_vector=unit_vector, unit_circle=unit_circle, title=title)
      # hide axes of the extra subplot (only when nplots is an odd number)
      if nx*ny &gt; nplots:
          axes[-1,-1].axis(&#39;off&#39;)
</pre></div>
</div>
</div>
</div>
<p>Helper functions</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Helper functions
def sort_evals_descending(evals, evectors):
  &quot;&quot;&quot;
  Sorts eigenvalues and eigenvectors in decreasing order. Also aligns first two
  eigenvectors to be in first two quadrants (if 2D).

  Args:
    evals (numpy array of floats)    : Vector of eigenvalues
    evectors (numpy array of floats) : Corresponding matrix of eigenvectors
                                        each column corresponds to a different
                                        eigenvalue

  Returns:
    (numpy array of floats)          : Vector of eigenvalues after sorting
    (numpy array of floats)          : Matrix of eigenvectors after sorting
  &quot;&quot;&quot;

  index = np.flip(np.argsort(evals))
  evals = evals[index]
  evectors = evectors[:, index]
  if evals.shape[0] == 2:
    if np.arccos(np.matmul(evectors[:, 0],
                           1 / np.sqrt(2) * np.array([1, 1]))) &gt; np.pi / 2:
      evectors[:, 0] = -evectors[:, 0]
    if np.arccos(np.matmul(evectors[:, 1],
                           1 / np.sqrt(2) * np.array([-1, 1]))) &gt; np.pi / 2:
      evectors[:, 1] = -evectors[:, 1]
  return evals, evectors

def calculate_cov_matrix(var_1, var_2, corr_coef):
  &quot;&quot;&quot;
  Calculates the covariance matrix based on the variances and
  correlation coefficient.

  Args:
    var_1 (scalar)         :  variance of the first random variable
    var_2 (scalar)         :  variance of the second random variable
    corr_coef (scalar)     :  correlation coefficient

  Returns:
    (numpy array of floats) : covariance matrix
  &quot;&quot;&quot;
  cov = corr_coef * np.sqrt(var_1 * var_2)
  cov_matrix = np.array([[var_1, cov], [cov, var_2]])
  return cov_matrix

def get_variance_explained(evals):
  &quot;&quot;&quot;
  Plots eigenvalues.

  Args:
    (numpy array of floats) : Vector of eigenvalues

  Returns:
    Nothing.

  &quot;&quot;&quot;

  # cumulatively sum the eigenvalues
  csum = np.cumsum(evals)
  # normalize by the sum of eigenvalues
  variance_explained = csum / np.sum(evals)

  return variance_explained

def add_noise(X, frac_noisy_pixels):
  &quot;&quot;&quot;
  Randomly corrupts a fraction of the pixels by setting them to random values.

  Args:
     X (numpy array of floats)  : Data matrix
     frac_noisy_pixels (scalar) : Fraction of noisy pixels

  Returns:
     (numpy array of floats)    : Data matrix + noise

  &quot;&quot;&quot;

  X_noisy = np.reshape(X, (X.shape[0] * X.shape[1]))
  N_noise_ixs = int(X_noisy.shape[0] * frac_noisy_pixels)
  noise_ixs = np.random.choice(X_noisy.shape[0], size=N_noise_ixs,
                               replace=False)
  X_noisy[noise_ixs] = np.random.uniform(0, 255, noise_ixs.shape)
  X_noisy = np.reshape(X_noisy, (X.shape[0], X.shape[1]))

  return X_noisy
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="key-concept-review-coding-tips">
<h1>Key concept review &amp; coding tips<a class="headerlink" href="#key-concept-review-coding-tips" title="Permalink to this headline">#</a></h1>
<section id="special-matrices">
<h2>Special matrices<a class="headerlink" href="#special-matrices" title="Permalink to this headline">#</a></h2>
<section id="diagonal-matrices">
<h3>Diagonal matrices<a class="headerlink" href="#diagonal-matrices" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Have only nonzero entries on the diagonal</p></li>
<li><p>Can be rectangular</p></li>
<li><p>Scales space</p></li>
<li><p>Inverse is diagonal matrix with inverse entries</p></li>
</ul>
</section>
<section id="orthogonal-matrices">
<h3>Orthogonal matrices<a class="headerlink" href="#orthogonal-matrices" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Square matrix where every column is a unit vector and every pair of columns is orthogonal</p></li>
<li><p>Rotates space</p></li>
<li><p>Its inverse is its transpose</p></li>
</ul>
</section>
<section id="symmetric-matrices">
<h3>Symmetric matrices<a class="headerlink" href="#symmetric-matrices" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Square matrix where <span class="math notranslate nohighlight">\(a_{ij} = a_{ji}\)</span></p></li>
<li><p>Equals its own transpose</p></li>
<li><p>Eigenvalues are always real (not complex)</p></li>
<li><p>Eigenvectors associated with different eigenvalues are orthogonal</p></li>
</ul>
</section>
</section>
<section id="matrix-decomposition">
<h2>Matrix decomposition<a class="headerlink" href="#matrix-decomposition" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Factorization of a matrix into a product of matrices</p></li>
<li><p>Product matrices might be more compact/ordered, could make computations easier, could shed light on matrix structure</p></li>
</ul>
<section id="eigendecomposition">
<h3>Eigendecomposition<a class="headerlink" href="#eigendecomposition" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(A = VDV^{-1}\)</span> where V has eigenvectors as columns and D is diagonal matrix with eigenvalues on the diagonal</p></li>
<li><p>Can only do this if A is square and if eigenvectors of A form a basis for space</p></li>
<li><p><span class="math notranslate nohighlight">\(A^n = VD^nV^{-1}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(A^{-1} = VD^{-1}V^{-1}\)</span></p></li>
</ul>
</section>
<section id="singular-value-decomposition">
<h3>Singular value decomposition<a class="headerlink" href="#singular-value-decomposition" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">np.linalg.svd</span></code></p></li>
<li><p><span class="math notranslate nohighlight">\(A = USV^T\)</span> where U/V are orthogonal matrices and S is diagonal</p></li>
<li><p>Can decompose any matrix this way</p></li>
<li><p>Diagonal entries of S are singular values, columns of U are left singular values, columns of V are right singular values</p></li>
<li><p>Decomposes transformation that matrix enacts into a rotation, then a scaling, then a rotation</p></li>
<li><p>Columns of V associated with zero or non-existant singular values form an orthogonal basis for the nullspace of A</p></li>
<li><p>Columns of U associated with non-zero singular values form an orthogonal basis for the column space of A</p></li>
<li><p>rank(A) = number of non-zero singular values</p></li>
<li><p>SVD factorizes A into sum of outer products with decreasing influence, can use first K sums to form rank K approximation of A</p></li>
</ul>
</section>
</section>
<section id="dimensionality-reduction">
<h2>Dimensionality Reduction<a class="headerlink" href="#dimensionality-reduction" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Transform data from high D to low D while keeping as much information as possible about the data (finding new representation for the data)</p></li>
<li><p>Can help with data visualization, noise reduction, data preprocessing for further analyses, and scientific findings, among other things</p></li>
</ul>
<section id="principal-components-analysis">
<h3>Principal components analysis<a class="headerlink" href="#principal-components-analysis" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sklearn.decomposition.pca</span></code> for PCA, see info at the end of this tutorial</p></li>
<li><p>Find axes in space that maximize the variance of the data (and minimize the residuals) while being orthongal to each other. Project data onto these axes and keep first K components</p></li>
<li><p>Can think of PCA as a change of basis where the new basis vectors are the principal components</p></li>
<li><p><span class="math notranslate nohighlight">\(U = XV\)</span> where U is the transformed data (# data points x reduced dim), X is the data matrix (# data points x orig dim), and V is the components matrix (orig dim x reduced dim)</p></li>
<li><p>Always center your data first!</p></li>
<li><p>Can find principal components as the eigenvectors of the covariance matrix (<span class="math notranslate nohighlight">\(\frac{1}{n}X^TX\)</span>), eigenvalues tell you the variance explained by that component (plot these to make a scree plot)</p></li>
<li><p>Could also use SVD to find PCA - the columns of V are the eigenvectors of the covariance matrix and the squared singular values over N are the eigenvalues</p></li>
</ul>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-1-delving-into-svd">
<h1>Exercise 1: Delving into SVD<a class="headerlink" href="#exercise-1-delving-into-svd" title="Permalink to this headline">#</a></h1>
<p>We’ll explore SVD by hand in this problem to help solidify our understanding of how the matrices interact with each other. Let $<span class="math notranslate nohighlight">\(A = \begin{bmatrix}
2 &amp; -4 \\
3 &amp; 1 \\
\end{bmatrix}, \bar{v} = \begin{bmatrix}
2 \\
1 \\
\end{bmatrix}\)</span>$</p>
<p>In the following plot, we’ll see the transformation that this matrix enacts.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>A = np.array([[2, -4], [3, 1]])
plot_linear_transformation(A)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Week5Tutorial1_11_0.png" src="../_images/Week5Tutorial1_11_0.png" />
</div>
</div>
<section id="a-computing-the-svd">
<h2>A) Computing the SVD<a class="headerlink" href="#a-computing-the-svd" title="Permalink to this headline">#</a></h2>
<p>Use <code class="docutils literal notranslate"><span class="pre">np.linalg.svd</span></code> to get the SVD of the matrix A. Note that the outputs are not quite the U, S, V we’ve been discussing. This function outputs <span class="math notranslate nohighlight">\(V^T\)</span> directly. Get S/V from the outputs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>U, s, VT = ...
S = ...
V = ...
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">VT</span> <span class="o">=</span> <span class="o">...</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">S</span> <span class="o">=</span> <span class="o">...</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">V</span> <span class="o">=</span> <span class="o">...</span>

<span class="ne">TypeError</span>: cannot unpack non-iterable ellipsis object
</pre></div>
</div>
</div>
</div>
</section>
<section id="b-svd-step-by-step-transformations">
<h2>B) SVD step by step transformations<a class="headerlink" href="#b-svd-step-by-step-transformations" title="Permalink to this headline">#</a></h2>
<p>Multiply out the operations of <span class="math notranslate nohighlight">\(V^T\)</span>, S, and U with vector <span class="math notranslate nohighlight">\(\bar{v}\)</span> one at a time. In other words, get <span class="math notranslate nohighlight">\(V^T\bar{v}\)</span>, then <span class="math notranslate nohighlight">\(SV^T\bar{v}\)</span>, then <span class="math notranslate nohighlight">\(USV^t\bar{v}\)</span>. You do not need to do this by hand - use code - but make sure you understand the matrix vector multiplication!</p>
<p>Make sure <span class="math notranslate nohighlight">\(USV^t\bar{v}\)</span> = <span class="math notranslate nohighlight">\(A\bar{v}\)</span>.</p>
<p>Execute the following cell to visualize the vectors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>v = ...
VTv = ...
SVTv = ...
USVTv = ...
Av = ...
print(USVTv)
print(Av)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ellipsis
Ellipsis
</pre></div>
</div>
</div>
</div>
<section id="id1">
<h3><a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>Execute to visualize vector transforms</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @title
# @markdown Execute to visualize vector transforms
vec_names = [r&#39;$\bar{v}$&#39;, r&#39;$SV^T\bar{v}$&#39;, r&#39;$V^T\bar{v}$&#39;, r&#39;A$\bar{v}$&#39;]
vecs = np.array([v, 
                 SVTv,
                 VTv,
                 USVTv])

fig, axes = plt.subplots(1, 1)
colors = plt.rcParams[&#39;axes.prop_cycle&#39;].by_key()[&#39;color&#39;]

axes.set(xlim=[-8, 8], ylim=[-8, 8])
axes.axis(&#39;Off&#39;)

for i_vec, vec in enumerate(vecs):    
  axes.arrow(0, 0, vec[0], vec[1], head_width=.2, facecolor=colors[i_vec], edgecolor=colors[i_vec], length_includes_head=True);
  axes.annotate(vec_names[i_vec], xy=(vec[0]+np.sign(vec[0])*.15, vec[1]+np.sign(vec[1])*.15), color=colors[i_vec]);

axes.plot([0, 0], [-8, 8], classic, alpha=.4);
axes.plot([-8, 8], [0, 0], classic, alpha=.4);

</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">line</span> <span class="mi">16</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span> <span class="n">axes</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;Off&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span> <span class="k">for</span> <span class="n">i_vec</span><span class="p">,</span> <span class="n">vec</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vecs</span><span class="p">):</span>    
<span class="ne">---&gt; </span><span class="mi">16</span>   <span class="n">axes</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">vec</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">vec</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">head_width</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i_vec</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i_vec</span><span class="p">],</span> <span class="n">length_includes_head</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span>   <span class="n">axes</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">vec_names</span><span class="p">[</span><span class="n">i_vec</span><span class="p">],</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">vec</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">vec</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">*</span><span class="mf">.15</span><span class="p">,</span> <span class="n">vec</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">vec</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="mf">.15</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i_vec</span><span class="p">]);</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="n">axes</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">classic</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">);</span>

<span class="ne">TypeError</span>: &#39;ellipsis&#39; object is not subscriptable
</pre></div>
</div>
</div>
</div>
<p>What transformation is happening to <span class="math notranslate nohighlight">\(\bar{v}\)</span> at each step?</p>
<p><strong>Your text answer</strong></p>
</section>
</section>
<section id="optional-c-low-rank-approximation">
<h2>(Optional) C) Low rank approximation<a class="headerlink" href="#optional-c-low-rank-approximation" title="Permalink to this headline">#</a></h2>
<p>We’ll explore successful low rank approximations of receptive fields in Tutorial 2 and this will make the concept much more intuitive - the goal of this problem is just to understand the computation involved and what a rank 1 approximation means.</p>
<p>Calculate a rank 1 approximation of A by hand. Specifically, compute:</p>
<div class="math notranslate nohighlight">
\[\text{Rank 1 approx } = B = s_1\bar{u}_1\bar{v}_1^T \]</div>
<p>where <span class="math notranslate nohighlight">\(s_1\)</span> is the first (highest) singular value and <span class="math notranslate nohighlight">\(\bar{u}_1\)</span> and <span class="math notranslate nohighlight">\(\bar{v}_1\)</span> are the corresponding columns of U and V.</p>
<p>Show your work for the computation! You should round to 2 places after the decimal.</p>
<p><strong>Your math answer</strong> show your work!</p>
<p>Compare B to the original matrix A. What does a rank 1 approximation mean? What is the computation “trying to do”? What is happening with the columns/rows of B?</p>
<p><strong>Your text answer here</strong></p>
<p>Note that the rank 1 approximation here is not great because our matrix is not anywhere close to rank 1! We would fully recover our matrix with a rank 2 approximation - <span class="math notranslate nohighlight">\( A = s_1\bar{u}_1\bar{v}_1^T + s_2\bar{u}_2\bar{v}_2^T\)</span> - since A is 2 x 2 and has maximum rank of 2.</p>
</section>
<section id="optional-extra-info-orthogonal-matrices-can-also-reflect">
<h2>(Optional) Extra info: Orthogonal matrices can also reflect<a class="headerlink" href="#optional-extra-info-orthogonal-matrices-can-also-reflect" title="Permalink to this headline">#</a></h2>
<p>Execute the next cell to visualize the transformation at each step of SVD (by <span class="math notranslate nohighlight">\(V^T\)</span>, then <span class="math notranslate nohighlight">\(S\)</span>, then <span class="math notranslate nohighlight">\(U\)</span>). You will notice that it isn’t simply rotation, then scaling, then a rotation. Both <span class="math notranslate nohighlight">\(V^T\)</span> and <span class="math notranslate nohighlight">\(U\)</span> enact a reflection in addition to a rotation. Orthogonal matrices can reflect in addition to rotating space.</p>
<p>We could get an SVD without reflection if we hadn’t ordered our columns by the size of the singular values.  If we switched the columns in U, S, and V, we would see just a rotation, then scaling, then another rotation (show below).</p>
<p>Execute this cell to visualize transformations</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute this cell to visualize transformations

plot_linear_transformations(VT, S, U, unit_vector=True, unit_circle=False)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">line</span> <span class="mi">3</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># @markdown Execute this cell to visualize transformations</span>
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="n">plot_linear_transformations</span><span class="p">(</span><span class="n">VT</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">unit_vector</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unit_circle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;VT&#39; is not defined
</pre></div>
</div>
</div>
</div>
<p>Execute this cell to visualize transformations with permuted columns</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute this cell to visualize transformations with permuted columns

plot_linear_transformations(V[:, [1, 0]].T, np.diag(s[::-1]), U[:, [1, 0]], unit_vector=True, unit_circle=False)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">9</span><span class="p">],</span> <span class="n">line</span> <span class="mi">3</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># @markdown Execute this cell to visualize transformations with permuted columns</span>
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="n">plot_linear_transformations</span><span class="p">(</span><span class="n">V</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">unit_vector</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unit_circle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;V&#39; is not defined
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-2-pca-implementation-and-correlation-exploration">
<h1>Exercise 2: PCA implementation and correlation exploration<a class="headerlink" href="#exercise-2-pca-implementation-and-correlation-exploration" title="Permalink to this headline">#</a></h1>
<section id="modified-from-nma-w1d5-t2">
<h2>Modified from NMA W1D5 T2<a class="headerlink" href="#modified-from-nma-w1d5-t2" title="Permalink to this headline">#</a></h2>
<p>In this exercise, you will implement PCA, apply it to 2 dimensional data, and examine the effects of correlations between dimensions.</p>
<p>Execute this cell to generate some data (X)</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute this cell to generate some data (X)
np.random.seed(123)
variance_1 = 1
variance_2 = 1
corr_coef = 0.8
cov_matrix = calculate_cov_matrix(variance_1, variance_2, corr_coef)
X =  np.random.multivariate_normal([5, 10], cov_matrix, size=1000)

fig, ax = plt.subplots()
ax.scatter(X[:,0], X[:, 1], s=1, color=&#39;#63BA79&#39;);
ax.spines[&#39;right&#39;].set_visible(False)
ax.spines[&#39;top&#39;].set_visible(False)

ax.set(xlabel=&#39;Neuron 1 activity&#39;, ylabel=&#39;Neuron 2 activity&#39;, xlim=[-5, 15], ylim=[-5, 15]);
</pre></div>
</div>
</div>
</div>
</section>
<section id="a-interactive-demo-identifying-first-principal-component">
<h2>A) Interactive Demo: Identifying first principal component<a class="headerlink" href="#a-interactive-demo-identifying-first-principal-component" title="Permalink to this headline">#</a></h2>
<p>Let’s take a subset of our data as shown below and mean subtract it. Play with the interactive demo. About which value of theta represents the first principal component? Why?</p>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Make sure you execute this cell to enable the widget!

def plot_potential_component(theta=180):
  n_points = 30

  mean_subtracted_X = X - np.mean(X, 0)

  fig, ax = plt.subplots()
  ax.spines[&#39;right&#39;].set_visible(False)
  ax.spines[&#39;top&#39;].set_visible(False)

  ax.set(xlabel=&#39;Neuron 1 activity&#39;, ylabel=&#39;Neuron 2 activity&#39;, xlim=[-5, 5], ylim=[-5, 5]);

  w = np.asarray([np.cos(theta*np.pi/180), np.sin(theta*np.pi/180)])[None, :];
  z = mean_subtracted_X[:n_points, :] @ w.T @ w;
  for i in range(n_points):
    ax.plot([mean_subtracted_X[i,0], z[i,0]], [mean_subtracted_X[i,1], z[i,1]], &#39;r&#39;)

  ax.plot(w[0, 0]*5*np.array([-1, 1]), w[0, 1]*5*np.array([-1, 1]), &#39;k&#39;)
  ax.scatter(z[:,0], z[:, 1],  color=&#39;r&#39;)
  ax.scatter(mean_subtracted_X[:n_points,0], mean_subtracted_X[:n_points, 1], color=&#39;#63BA79&#39;);


_ = widgets.interact(plot_potential_component, theta = (0, 180, 1), fontsize=60)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "2e039a8d0da246a086d64bfe90b2f271"}
</script></div>
</div>
<p><strong>Your text answer</strong></p>
</section>
<section id="b-implement-pca">
<h2>B) Implement PCA<a class="headerlink" href="#b-implement-pca" title="Permalink to this headline">#</a></h2>
<p>Let’s first implement PCA! We will build a function that takes in data and returns the transformed data, the principal components, and the variance explained by each component.</p>
<p>We will use an implementation involving the eigenvectors/eigenvalues of the covariance matrix (as opposed to using SVD).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def pca(X):
  &quot;&quot;&quot;
  Sorts eigenvalues and eigenvectors in decreasing order.

  Args:
    X (numpy array of floats): Data matrix each column corresponds to a
                               different random variable 

  Returns:
    (numpy array of floats)  : Data projected onto the new basis
    (numpy array of floats)  : Vector of eigenvalues
    (numpy array of floats)  : Corresponding matrix of eigenvectors

  &quot;&quot;&quot;

  # Subtract the mean of X
  X = ...

  # Calculate the sample covariance matrix
  cov_matrix = ... # hint: covariance matrix = (1/n)X^TX

  # Calculate the eigenvalues and eigenvectors
  evals, evectors = ... # hint: use np.linalg.eig

  # Sort the eigenvalues in descending order using a helper function
  evals, evectors = sort_evals_descending(evals, evectors)

  # Project the data onto the new eigenvector basis
  transformed_data = ... # hint: remember U = XV
  
  return transformed_data, evectors, evals

# Uncomment below once you have filled in the above function

# Perform PCA on the data matrix X
#X_pca, evectors, evals = pca(X)

# Plot the data projected into the new basis
#plot_pca_transformation(X, X_pca)
</pre></div>
</div>
</div>
</div>
<p>Note that the correlation between dimensions goes to 0 after the transformation to the principal components basis! This is a property of PCA: it decorrelates the data.</p>
</section>
<section id="c-visualize-variance-explained">
<h2>C) Visualize variance explained<a class="headerlink" href="#c-visualize-variance-explained" title="Permalink to this headline">#</a></h2>
<p>We want to create a plot telling us the percent of variance explained by each principal component (here we have just two). Determine what information you need for this (the inputs) and complete the function below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plot_variances(...):

   percent_explained_variance = ...

   fig, ax = plt.subplots() 
   colors = plt.rcParams[&#39;axes.prop_cycle&#39;].by_key()[&#39;color&#39;]
   ax.plot(percent_explained_variance, &#39;-o&#39;, color=colors[4])
   ax.set(ylim=[0, 1], ylabel=&#39;% Explained Variance&#39;, xlabel=&#39;Component number&#39;, xticks=np.arange(len(percent_explained_variance)))
   
plot_variances(...)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>  <span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">13</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
    <span class="k">def</span> <span class="nf">plot_variances</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
                       <span class="o">^</span>
<span class="ne">SyntaxError</span>: invalid syntax
</pre></div>
</div>
</div>
</div>
</section>
<section id="d-interactive-demo-exploration-of-the-correlation-coefficient">
<h2>D) Interactive Demo: Exploration of the correlation coefficient<a class="headerlink" href="#d-interactive-demo-exploration-of-the-correlation-coefficient" title="Permalink to this headline">#</a></h2>
<p>Run the following cell and use the slider to change the correlation coefficient of the data. This will update a plot of the data with the principal components overlaid and a plot of percentage of explained variance.</p>
<p><strong>Questions:</strong></p>
<ul class="simple">
<li><p>Can you find a correlation coefficient value for which the components have equal explained variance?</p></li>
<li><p>Can you find a value for which only only one component explains any variance?</p></li>
</ul>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Make sure you execute this cell to enable the widget!

def refresh(corr_coef=.8):
  cov_matrix = calculate_cov_matrix(variance_1, variance_2, corr_coef)
  X = X =  np.random.multivariate_normal([0, 0], cov_matrix, size=1000)
  score, evectors, evals = pca(X)
  plot_data_and_PCs(X, evectors)
  plot_variances(evals)

_ = widgets.interact(refresh, corr_coef=(-1, 1, .1), fontsize=60)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "d04802fe2bbf4f4d9d66b44f1ec6b82e"}
</script></div>
</div>
<p><strong>Your text answer</strong></p>
</section>
<section id="optional-advanced-challenge-pca-implementation-with-svd">
<h2>Optional advanced challenge: PCA implementation with SVD<a class="headerlink" href="#optional-advanced-challenge-pca-implementation-with-svd" title="Permalink to this headline">#</a></h2>
<p>Take the PCA function from part A and implement with SVD instead of with the eigenvectors of the covariance matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def pca_with_SVD(X):

    ...
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-3-pca-of-images">
<h1>Exercise 3: PCA of images<a class="headerlink" href="#exercise-3-pca-of-images" title="Permalink to this headline">#</a></h1>
<section id="modified-from-nma-w1d5-t3">
<h2>Modified from NMA W1D5 T3<a class="headerlink" href="#modified-from-nma-w1d5-t3" title="Permalink to this headline">#</a></h2>
<p>In this exercise, we will look at the PCA of images. We will use images from the MNIST dataset, which is a dataset of handdrawn numbers (0-9). We’re using this data instead of more neuroscience related data because it’s a small dataset that’s easy to interpret. Everything we will learn here could be applied to, for example, the frames of a video of a mouse performing a task.</p>
<p>The MNIST dataset consists of a 70,000 images of individual handwritten digits. Each image is a 28x28 pixel grayscale image. For convenience, each 28x28 pixel image is often unravelled into a single 784 (=28*28) element vector (a process called flattening the images), so that the whole dataset is represented as a 70,000 x 784 matrix. Each row represents a different image, and each column represents a different pixel.</p>
<p>Execute the following cell to load the MNIST dataset and plot the first nine images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.datasets import fetch_openml
mnist = fetch_openml(name=&#39;mnist_784&#39;)
X = np.array(mnist.data)
plot_sample_images(X)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">16</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;sklearn&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="a-explained-variances">
<h2>A) Explained variances<a class="headerlink" href="#a-explained-variances" title="Permalink to this headline">#</a></h2>
<p>We will first perform PCA and plot the cumulative percentage explained variance over components. Note that this is related to our earlier plots but now we are plotting the percentage of explained variance <strong>cumulatively</strong>. Execute the next cell to do this.</p>
<ul class="simple">
<li><p>How many principal components are required to explain 90% of the variance?</p></li>
<li><p>How does the intrinsic dimensionality of this dataset compare to its extrinsic dimensionality?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>transformed_data, evectors, evals = pca(X)
variance_explained = get_variance_explained(evals)
plot_variance_explained(variance_explained)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">17</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">transformed_data</span><span class="p">,</span> <span class="n">evectors</span><span class="p">,</span> <span class="n">evals</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">variance_explained</span> <span class="o">=</span> <span class="n">get_variance_explained</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">plot_variance_explained</span><span class="p">(</span><span class="n">variance_explained</span><span class="p">)</span>

<span class="nn">Cell In[12], line 23,</span> in <span class="ni">pca</span><span class="nt">(X)</span>
<span class="g g-Whitespace">     </span><span class="mi">20</span> <span class="n">cov_matrix</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># hint: covariance matrix = (1/n)X^TX</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span> <span class="c1"># Calculate the eigenvalues and eigenvectors</span>
<span class="ne">---&gt; </span><span class="mi">23</span> <span class="n">evals</span><span class="p">,</span> <span class="n">evectors</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># hint: use np.linalg.eig</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span> <span class="c1"># Sort the eigenvalues in descending order using a helper function</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span> <span class="n">evals</span><span class="p">,</span> <span class="n">evectors</span> <span class="o">=</span> <span class="n">sort_evals_descending</span><span class="p">(</span><span class="n">evals</span><span class="p">,</span> <span class="n">evectors</span><span class="p">)</span>

<span class="ne">TypeError</span>: cannot unpack non-iterable ellipsis object
</pre></div>
</div>
</div>
</div>
<p><strong>Your text answer</strong></p>
</section>
<section id="b-pca-reconstruction">
<h2>B) PCA Reconstruction<a class="headerlink" href="#b-pca-reconstruction" title="Permalink to this headline">#</a></h2>
<p>Let’s try projecting down onto our reduced dimensionality PCA space and then <strong>reconstructing</strong> our images from the low-D space.</p>
<p>To see this, recall that to perform PCA we projected the data <span class="math notranslate nohighlight">\(\bf X\)</span> onto the eigenvectors of the covariance matrix:</p>
<div class="amsmath math notranslate nohighlight" id="equation-30181c7f-9e32-4e8b-8f2e-e790862c1572">
<span class="eqno">(1)<a class="headerlink" href="#equation-30181c7f-9e32-4e8b-8f2e-e790862c1572" title="Permalink to this equation">#</a></span>\[\begin{equation}
\bf U = X V
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(U\)</span> is the transformed data, <span class="math notranslate nohighlight">\(X\)</span> is the data matrix, and <span class="math notranslate nohighlight">\(V\)</span> is the components matrix.</p>
<p>Since <span class="math notranslate nohighlight">\(\bf V\)</span> is an orthogonal matrix, <span class="math notranslate nohighlight">\({\bf V}^{-1} = {\bf V}^T\)</span>. We can reconstruct by:</p>
<div class="amsmath math notranslate nohighlight" id="equation-13f47047-486d-4776-89e8-052beeed563a">
<span class="eqno">(2)<a class="headerlink" href="#equation-13f47047-486d-4776-89e8-052beeed563a" title="Permalink to this equation">#</a></span>\[\begin{equation}
\bf X = U V^T
\end{equation}\]</div>
<p>To reconstruct the data from a low-dimensional approximation, we just have to truncate these matrices.  Let’s call <span class="math notranslate nohighlight">\({\bf U}_{1:K}\)</span> and <span class="math notranslate nohighlight">\({\bf V}_{1:K}\)</span> as keeping only the first <span class="math notranslate nohighlight">\(K\)</span> columns of this matrix. Then our reconstruction is:</p>
<div class="amsmath math notranslate nohighlight" id="equation-80498292-78ae-4bce-bda9-6ee72f03a5ed">
<span class="eqno">(3)<a class="headerlink" href="#equation-80498292-78ae-4bce-bda9-6ee72f03a5ed" title="Permalink to this equation">#</a></span>\[\begin{equation}
{\bf \hat X = U}_{1:K} ({\bf V}_{1:K})^T.
\end{equation}\]</div>
<p>Complete the following function to reconstruct the images from the top K components.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def reconstruct_data(transformed_data, evectors, X_mean, K):
  &quot;&quot;&quot;
  Reconstruct the data based on the top K components.

  Args:
    transformed_data (numpy array of floats)    : data projected onto PCA basis
    evectors (numpy array of floats) : Matrix of eigenvectors
    X_mean (numpy array of floats)   : Vector corresponding to data mean
    K (scalar)                       : Number of components to include

  Returns:
    (numpy array of floats)          : Matrix of reconstructed data

  &quot;&quot;&quot;

  #################################################
  ## TO DO for students: Reconstruct the original data in X_reconstructed
  # Comment once you&#39;ve filled in the function
  raise NotImplementedError(&quot;Student exercise: reconstructing data function!&quot;)
  #################################################

  # Reconstruct the data from the score and eigenvectors
  # Don&#39;t forget to add the mean!!
  X_reconstructed =  ...

  return X_reconstructed


K = 100

# Fill in below then uncomment the last line

# Reconstruct the data based on all components
X_mean = ...
X_reconstructed = reconstruct_data()

# Plot the data and reconstruction
# plot_reconstructions(X, X_reconstructed)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">18</span><span class="p">],</span> <span class="n">line</span> <span class="mi">35</span>
<span class="g g-Whitespace">     </span><span class="mi">31</span> <span class="c1"># Fill in below then uncomment the last line</span>
<span class="g g-Whitespace">     </span><span class="mi">32</span> 
<span class="g g-Whitespace">     </span><span class="mi">33</span> <span class="c1"># Reconstruct the data based on all components</span>
<span class="g g-Whitespace">     </span><span class="mi">34</span> <span class="n">X_mean</span> <span class="o">=</span> <span class="o">...</span>
<span class="ne">---&gt; </span><span class="mi">35</span> <span class="n">X_reconstructed</span> <span class="o">=</span> <span class="n">reconstruct_data</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">37</span> <span class="c1"># Plot the data and reconstruction</span>
<span class="g g-Whitespace">     </span><span class="mi">38</span> <span class="c1"># plot_reconstructions(X, X_reconstructed)</span>

<span class="ne">TypeError</span>: reconstruct_data() missing 4 required positional arguments: &#39;transformed_data&#39;, &#39;evectors&#39;, &#39;X_mean&#39;, and &#39;K&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="c-interactive-demo-reconstruct-the-data-matrix-using-different-numbers-of-pcs">
<h2>C) Interactive Demo: Reconstruct the data matrix using different numbers of PCs<a class="headerlink" href="#c-interactive-demo-reconstruct-the-data-matrix-using-different-numbers-of-pcs" title="Permalink to this headline">#</a></h2>
<p>Now run the code below and experiment with the slider to reconstruct the data matrix using different numbers of principal components.</p>
<ul class="simple">
<li><p>How many principal components are necessary to reconstruct the numbers (by eye)? How does this relate to the intrinsic dimensionality of the data?</p></li>
<li><p>Do you see any information in the data with only a single principal component?</p></li>
</ul>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Make sure you execute this cell to enable the widget!


def refresh(K=100):
  X_reconstructed = reconstruct_data(transformed_data, evectors, X_mean, K)
  plot_reconstructions(X, X_reconstructed)
  plt.title(&#39;Reconstructed, K={}&#39;.format(K))


_ = widgets.interact(refresh, K=(1, 784, 10))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "f21b0c126d8b4696b1c6454592e23b66"}
</script></div>
</div>
<p><strong>Your text answer</strong></p>
</section>
<section id="d-visualization-of-the-principal-components">
<h2>D) Visualization of the principal components<a class="headerlink" href="#d-visualization-of-the-principal-components" title="Permalink to this headline">#</a></h2>
<p>We can visualize the principal components as images by reversing the flattening. Here we plot using a differenet colormap than black &amp; white as it highlights more structure.</p>
<ul class="simple">
<li><p>What structure do you see in the first principal component? What kinds of images would this basis vector differentiate?</p></li>
<li><p>Try visualizing the second and third basis vectors. Do you see any structure? What about the 100th basis vector? 500th? 700th?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>  plot_principal_components(evectors[:, 0])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">20</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">plot_principal_components</span><span class="p">(</span><span class="n">evectors</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>

<span class="ne">NameError</span>: name &#39;evectors&#39; is not defined
</pre></div>
</div>
</div>
</div>
<p><strong>Your text answer</strong></p>
</section>
<section id="read-only-e-denoising-with-pca">
<h2>(Read only) E) Denoising with PCA<a class="headerlink" href="#read-only-e-denoising-with-pca" title="Permalink to this headline">#</a></h2>
<p>We will add some noise to our images to see how PCA reconstructions can be helpful for reducing noise. In this case, we will set 20% of the pixels to random values. We will then visualize some of the noisy images and the resulting cumulative variance explained plot.</p>
<p>In the next cell, we will project the images onto the original PCA space (from the clean, not noisy, data) and then reconstruct from the top 50 components. Observe that this removes the noise quite effectively!</p>
<p>Execute this cell to visualize noisy data</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute this cell to visualize noisy data
np.random.seed(2020)  # set random seed
X_noisy = add_noise(X, .2)
score_noisy, evectors_noisy, evals_noisy = pca(X_noisy)
variance_explained_noisy = get_variance_explained(evals_noisy)


plot_sample_images(X_noisy)
plot_variance_explained(variance_explained_noisy)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">21</span><span class="p">],</span> <span class="n">line</span> <span class="mi">4</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2020</span><span class="p">)</span>  <span class="c1"># set random seed</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">X_noisy</span> <span class="o">=</span> <span class="n">add_noise</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">.2</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="n">score_noisy</span><span class="p">,</span> <span class="n">evectors_noisy</span><span class="p">,</span> <span class="n">evals_noisy</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">variance_explained_noisy</span> <span class="o">=</span> <span class="n">get_variance_explained</span><span class="p">(</span><span class="n">evals_noisy</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="n">plot_sample_images</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">)</span>

<span class="nn">Cell In[12], line 23,</span> in <span class="ni">pca</span><span class="nt">(X)</span>
<span class="g g-Whitespace">     </span><span class="mi">20</span> <span class="n">cov_matrix</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># hint: covariance matrix = (1/n)X^TX</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span> <span class="c1"># Calculate the eigenvalues and eigenvectors</span>
<span class="ne">---&gt; </span><span class="mi">23</span> <span class="n">evals</span><span class="p">,</span> <span class="n">evectors</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># hint: use np.linalg.eig</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span> <span class="c1"># Sort the eigenvalues in descending order using a helper function</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span> <span class="n">evals</span><span class="p">,</span> <span class="n">evectors</span> <span class="o">=</span> <span class="n">sort_evals_descending</span><span class="p">(</span><span class="n">evals</span><span class="p">,</span> <span class="n">evectors</span><span class="p">)</span>

<span class="ne">TypeError</span>: cannot unpack non-iterable ellipsis object
</pre></div>
</div>
</div>
</div>
<p>Execute to visualize denoised reconstructions</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute to visualize denoised reconstructions
X_noisy_mean = np.mean(X_noisy, 0)
projX_noisy = np.matmul(X_noisy - X_noisy_mean, evectors)
X_reconstructed = reconstruct_data(projX_noisy, evectors, X_noisy_mean, 50)

plot_reconstructions(X_noisy, X_reconstructed)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">22</span><span class="p">],</span> <span class="n">line</span> <span class="mi">3</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># @markdown Execute to visualize denoised reconstructions</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">X_noisy_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="n">projX_noisy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X_noisy</span> <span class="o">-</span> <span class="n">X_noisy_mean</span><span class="p">,</span> <span class="n">evectors</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">X_reconstructed</span> <span class="o">=</span> <span class="n">reconstruct_data</span><span class="p">(</span><span class="n">projX_noisy</span><span class="p">,</span> <span class="n">evectors</span><span class="p">,</span> <span class="n">X_noisy_mean</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">plot_reconstructions</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">,</span> <span class="n">X_reconstructed</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;evectors&#39; is not defined
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="extra-info-pca-sklearn">
<h1>Extra info: PCA &amp; Sklearn<a class="headerlink" href="#extra-info-pca-sklearn" title="Permalink to this headline">#</a></h1>
<p>In this tutorial, we created our own functions to compute PCA and reconstruct images so we could better understand the algorithms. Usually though, you would  use <code class="docutils literal notranslate"><span class="pre">sklearn.decomposition.pca</span></code> to perform PCA. Sklearn is a class based package - I have a video explaining the basics of class based programming (object oriented programming) and a video on sklearn as part of my Pandemic Python for Neuroscientists course so check that out if interested.
I’ll demonstrate the basics here using some data with 3 features (X).</p>
<p>See docs here: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html</p>
<p>Execute to generate some data X</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>#  @markdown Execute to generate some data X
np.random.seed(123)
variance_1 = 1
variance_2 = 1
corr_coef = 0.8
cov_matrix = np.array([[1, .2, .3], [.2, 1, .3], [.3, .3, 1]])
X =  np.random.multivariate_normal([5, 10, 2], cov_matrix, size=1000)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Import PCA class
from sklearn.decomposition import PCA

# Set up model, tell it the number of components you&#39;ll want to keep (if not set, all components will be kept)
pca = PCA(n_components=2)

# Fit the model to your data, aka find the principal components
pca.fit(X)

# Now you can access the principal components
print(pca.components_)

# And the % of explained variance for each component
print(pca.explained_variance_ratio_)

# You can transform your data now
transformed_data = pca.transform(X)

# You could have fit and transformed at the same time if you had wanted
transformed_data = pca.fit_transform(X)

# You can also reconstruct into the original space
reconstruction = pca.inverse_transform(transformed_data)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">24</span><span class="p">],</span> <span class="n">line</span> <span class="mi">2</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Import PCA class</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="c1"># Set up model, tell it the number of components you&#39;ll want to keep (if not set, all components will be kept)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;sklearn&#39;
</pre></div>
</div>
</div>
</div>
</section>


<script type="application/vnd.jupyter.widget-state+json">
{"state": {"c0e343e03dc94a54bb5a3c95cde2a861": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "56f0ac6c4bd84c0eab9bd37a6f402ef7": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c0c2a82c68354e75a0cf19229bf9a18c": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": [], "layout": "IPY_MODEL_56f0ac6c4bd84c0eab9bd37a6f402ef7"}}, "2e039a8d0da246a086d64bfe90b2f271": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_f0432af92b8d4b0d99878a27031bb4ea", "IPY_MODEL_5dcc1b22efc44820bdadac12f5856f9a"], "layout": "IPY_MODEL_56f0ac6c4bd84c0eab9bd37a6f402ef7"}}, "132b967bd8bd4f188d1b555bff2ca244": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b2aae7ef4e034f07be288bdc220fdf9e": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "3c31e877b4e546aaaca7fb9274746af5": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "1bb655045a714fb793435b9f7159d544": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "c93a196aafea45f4b1042e146e9d46da": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_b2aae7ef4e034f07be288bdc220fdf9e", "max": 180, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_1bb655045a714fb793435b9f7159d544", "value": 90}}, "f0432af92b8d4b0d99878a27031bb4ea": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "theta", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_b2aae7ef4e034f07be288bdc220fdf9e", "max": 180, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_1bb655045a714fb793435b9f7159d544", "value": 180}}, "5b01485b44e34bd180f528c1a5570f25": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9430b4aa4caf4eed8e4ac8d7bfc4ceda": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "45d3c8950765470aa34303ab841249b9": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_9430b4aa4caf4eed8e4ac8d7bfc4ceda", "msg_id": "", "outputs": []}}, "5dcc1b22efc44820bdadac12f5856f9a": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_9430b4aa4caf4eed8e4ac8d7bfc4ceda", "msg_id": "", "outputs": []}}, "3d2215aabeef4f5ba9a65c51aff85b75": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "fcda5fb4c0254c2bbece52a2f4bc8917": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "43bc92ae69b7418c9a05c205357049b2": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": [], "layout": "IPY_MODEL_fcda5fb4c0254c2bbece52a2f4bc8917"}}, "d04802fe2bbf4f4d9d66b44f1ec6b82e": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_8937b9c8341b4c878949819c8a199748", "IPY_MODEL_80e2d248dfa3493d97b028e252707603"], "layout": "IPY_MODEL_fcda5fb4c0254c2bbece52a2f4bc8917"}}, "133c644c91e74787be2beb13c3071f1b": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d2ff1ba696444844939719fa26c60f43": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "140574ca983748f684545dea4c042f02": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "40f496c6a519413db188bacea3ea281d": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "81fc10e64b54480691592403822bfe64": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_d2ff1ba696444844939719fa26c60f43", "max": 1.0, "min": -1.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_40f496c6a519413db188bacea3ea281d", "value": 0.0}}, "8937b9c8341b4c878949819c8a199748": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "corr_coef", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_d2ff1ba696444844939719fa26c60f43", "max": 1.0, "min": -1.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_40f496c6a519413db188bacea3ea281d", "value": 0.8}}, "739e9f5487784ffabcb245c1e617c98b": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "73d5a730b22047d4a43b4f6a1c99c628": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "64c8c0d6a43847b6aef8c2ae1e1723bf": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_73d5a730b22047d4a43b4f6a1c99c628", "msg_id": "", "outputs": []}}, "80e2d248dfa3493d97b028e252707603": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_73d5a730b22047d4a43b4f6a1c99c628", "msg_id": "", "outputs": [{"output_type": "error", "ename": "TypeError", "evalue": "cannot unpack non-iterable ellipsis object", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)", "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/ipywidgets/widgets/interaction.py:257\u001b[0m, in \u001b[0;36minteractive.update\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    255\u001b[0m     value \u001b[38;5;241m=\u001b[39m widget\u001b[38;5;241m.\u001b[39mget_interact_value()\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[widget\u001b[38;5;241m.\u001b[39m_kwarg] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m show_inline_matplotlib_plots()\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_display \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n", "Cell \u001b[0;32mIn[14], line 6\u001b[0m, in \u001b[0;36mrefresh\u001b[0;34m(corr_coef)\u001b[0m\n\u001b[1;32m      4\u001b[0m cov_matrix \u001b[38;5;241m=\u001b[39m calculate_cov_matrix(variance_1, variance_2, corr_coef)\n\u001b[1;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m=\u001b[39m  np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmultivariate_normal([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], cov_matrix, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m score, evectors, evals \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m plot_data_and_PCs(X, evectors)\n\u001b[1;32m      8\u001b[0m plot_variances(evals)\n", "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mpca\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     20\u001b[0m cov_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m \u001b[38;5;66;03m# hint: covariance matrix = (1/n)X^TX\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate the eigenvalues and eigenvectors\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m evals, evectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m \u001b[38;5;66;03m# hint: use np.linalg.eig\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Sort the eigenvalues in descending order using a helper function\u001b[39;00m\n\u001b[1;32m     26\u001b[0m evals, evectors \u001b[38;5;241m=\u001b[39m sort_evals_descending(evals, evectors)\n", "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable ellipsis object"]}]}}, "317d02810dc144a29710b37f1661567e": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "fb327c23309541b6866e1d49058a3c52": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "559350bf85c54b11bae7f876acf86944": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": [], "layout": "IPY_MODEL_fb327c23309541b6866e1d49058a3c52"}}, "f21b0c126d8b4696b1c6454592e23b66": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_86050faf12bf444f8c5b0d3ea30425db", "IPY_MODEL_0c113910ec2a40ccbb5021a19cb2899e"], "layout": "IPY_MODEL_fb327c23309541b6866e1d49058a3c52"}}, "6cc860ae2e8c4f15880999c05bc33cc0": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "91c88bd6f54542c4a7ce4ac4367e6c56": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "594dbc5b2bb54611bce419a4196dbe5e": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "ce8e4fe4fde7436c89b6e0382eabb3fe": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "a6e0560aa06a488cbdeb1b99a624497a": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_91c88bd6f54542c4a7ce4ac4367e6c56", "max": 784, "min": 1, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 10, "style": "IPY_MODEL_ce8e4fe4fde7436c89b6e0382eabb3fe", "value": 391}}, "86050faf12bf444f8c5b0d3ea30425db": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "K", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_91c88bd6f54542c4a7ce4ac4367e6c56", "max": 784, "min": 1, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 10, "style": "IPY_MODEL_ce8e4fe4fde7436c89b6e0382eabb3fe", "value": 100}}, "7b97d729e6114d0fb2edf48c9625f8cf": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5e76cb7481d14c6dbca41c350de8b9b9": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "95646d61162d4d14bf1ff382007b5403": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_5e76cb7481d14c6dbca41c350de8b9b9", "msg_id": "", "outputs": []}}, "0c113910ec2a40ccbb5021a19cb2899e": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_5e76cb7481d14c6dbca41c350de8b9b9", "msg_id": "", "outputs": [{"output_type": "error", "ename": "NameError", "evalue": "name 'transformed_data' is not defined", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "File \u001b[0;32m/opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/ipywidgets/widgets/interaction.py:257\u001b[0m, in \u001b[0;36minteractive.update\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    255\u001b[0m     value \u001b[38;5;241m=\u001b[39m widget\u001b[38;5;241m.\u001b[39mget_interact_value()\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[widget\u001b[38;5;241m.\u001b[39m_kwarg] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m show_inline_matplotlib_plots()\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_display \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n", "Cell \u001b[0;32mIn[19], line 5\u001b[0m, in \u001b[0;36mrefresh\u001b[0;34m(K)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrefresh\u001b[39m(K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m   X_reconstructed \u001b[38;5;241m=\u001b[39m reconstruct_data(\u001b[43mtransformed_data\u001b[49m, evectors, X_mean, K)\n\u001b[1;32m      6\u001b[0m   plot_reconstructions(X, X_reconstructed)\n\u001b[1;32m      7\u001b[0m   plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReconstructed, K=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(K))\n", "\u001b[0;31mNameError\u001b[0m: name 'transformed_data' is not defined"]}]}}}, "version_major": 2, "version_minor": 0}
</script>


    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ebatty/MathToolsforNeuroscience",
            ref: "jupyterbook",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Week5"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Video53.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Video 5.3: PCA</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Week5Tutorial2.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Tutorial 2</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ella Batty<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>