{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyPd1GxKXzLAvVZk/fTTTbdH",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ebatty/MathToolsforNeuroscience/blob/jupyterbook/Week7/Week7Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9l0lyqLvkW7"
   },
   "source": [
    "# Week 7: Probability & Statistics II\n",
    "\n",
    "# Tutorial 1\n",
    "\n",
    "# [insert your name]\n",
    "\n",
    "**Important reminders**: Before starting, click \"File -> Save a copy in Drive\". Produce a pdf for submission by \"File -> Print\" and then choose \"Save to PDF\".\n",
    "\n",
    "To complete this tutorial, you should have watched Videos 7.1 - 7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cv9HSBNPyLV9",
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Imports\n",
    "\n",
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets  # interactive display\n",
    "import math"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Plotting functions\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZIdPVYl9TzmK",
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Plotting functions\n",
    "import numpy\n",
    "from numpy.linalg import inv, eig\n",
    "from math import ceil\n",
    "from matplotlib import pyplot, ticker, get_backend, rc\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcmzPav651kP"
   },
   "source": [
    "# Exercise 1: Clarifying Correlation\n",
    "\n",
    "There are a lot of misunderstandings over what information correlation coefficients capture so let's make completely sure we understand this descriptive statistics. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljQ-7zaA7xpy"
   },
   "source": [
    "## A) Simulate data\n",
    "\n",
    "We are looking at two variables, x and y, and the relationship between them. We will simulate x from a normal distribution with mean 5 and standard deviation 1.  \n",
    "$$ x = N(5 | 1)$$\n",
    "\n",
    "This notation $N(\\mu | \\sigma)$ denotes a normal (Gaussian) distribution with mean $\\mu$ and standard deviation $\\sigma$. \n",
    "\n",
    "We will model y as:\n",
    "\n",
    "$$ y = c (x + N (0, \\sigma)) + N(0, \\sigma)$$\n",
    "c here is a constant the determines the slope of the relationship and $\\sigma$ denotes the size of the noise added to get y (added to x before multiplication with the slope and again afterwards).\n",
    "\n",
    "Complete the function below to simulate x and y for a given slope and noise standard deviation and compute the correlation coefficient between them. You can use `np.random.normal` and `np.corrcoef` which gives the Pearson correlation coefficient (the commonly used metric), which measures the linear correlation between two variables as:\n",
    "\n",
    "$$ r = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i - \\bar{x})^2\\sum(y_i - \\bar{y})^2}} $$\n",
    "\n",
    "Hint: a normal distribution $N(\\mu | \\sigma)$ is equivalent to $\\mu + \\sigma N(0|1)$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TD17f2-H8fML"
   },
   "source": [
    "def simulate_data(slope, noise_sd, n_data_points = 300):\n",
    "\n",
    "  # Simulate x\n",
    "  x = ...\n",
    "\n",
    "  # Simulate y\n",
    "  y = ...\n",
    "  \n",
    "  # Get correlation coefficient\n",
    "  corr_coef = ...\n",
    "\n",
    "  return x, y, corr_coef\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRADHKqP6JEI"
   },
   "source": [
    "## A) Correlation vs noise\n",
    "We will first assume the slope is equal to 2 and vary the standard deviation of the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Execute this cell to plot simulated data\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g8GrR6Ig9Qbr",
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Execute this cell to plot simulated data\n",
    "slope = 2\n",
    "noise_sds = np.arange(0, 10, 2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4)) #, sharey=True, sharex=True)\n",
    "r, c = (0, 0)\n",
    "\n",
    "corr_coefs = np.zeros((noise_sds.shape[0],))\n",
    "for i_noise, noise_sd in enumerate(noise_sds):\n",
    "  x, y, corr_coef = simulate_data(slope, noise_sd)\n",
    "  corr_coefs[i_noise] = corr_coef\n",
    "  axes[i_noise].plot(x, y, '.')\n",
    "  axes[i_noise].set_aspect('auto')\n",
    "  c+=1\n",
    "  if c > 4:\n",
    "    r += 1\n",
    "    c = 0\n",
    "  axes[i_noise].set(title ='Noise sd = '+str(noise_sd), xlabel = 'x')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5OE7lUBA6C0"
   },
   "source": [
    "**Before executing next cell** Guess the correlation coefficient for each of these 5 plots and draw a plot of those correlation coefficients vs the noise (so y axis is correlation coefficient and x axis is noise sd). Note that this graph won't be graded on accuracy but you will be expected to submit it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlK78yfBGOQz"
   },
   "source": [
    "### **Answer**\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "Put your graph here\n",
    "</font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3PXtwtuB1t5"
   },
   "source": [
    "Now we will look at the actual graph below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " AFTER PREVIOUS STEP: Execute this cell to plot correlation coefficients vs noise sd\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Wj_-f_eI-Yo2",
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown AFTER PREVIOUS STEP: Execute this cell to plot correlation coefficients vs noise sd\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.plot(noise_sds, corr_coefs, 'o-', c='#70E0BD', lw=3)\n",
    "\n",
    "ax.set(title='Correlation coefficient vs noise', xlabel='Noise sd', ylabel='Corr coeff');"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqSldmylCC8p"
   },
   "source": [
    "Does this graph look different than the one you had predicted? If so, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMrE2H0ZGSWL"
   },
   "source": [
    "### **Answer**\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "Text answer here\n",
    "</font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3qlbUEd6OTO"
   },
   "source": [
    "## B) Correlation vs slope of relationship\n",
    "\n",
    "Now we will assume a constant standard deviation of 1 and vary the slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Execute this cell to plot simulated data\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2OwX4Qc_6P9d",
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Execute this cell to plot simulated data\n",
    "noise_sd = 1\n",
    "slopes = np.arange(-8, 9, 2)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(slopes), figsize=(20, 4), sharey=True, sharex=True)\n",
    "r, c = (0, 0)\n",
    "\n",
    "corr_coefs = np.zeros((slopes.shape[0],))\n",
    "for i_slope, slope in enumerate(slopes):\n",
    "  x, y, corr_coef = simulate_data(slope, noise_sd)\n",
    "  corr_coefs[i_slope] = corr_coef\n",
    "  axes[i_slope].plot(x, y, '.')\n",
    "  axes[i_slope].set_aspect('auto')\n",
    "  c+=1\n",
    "  if c > 4:\n",
    "    r += 1\n",
    "    c = 0\n",
    "  axes[i_slope].set(title ='Slope = '+str(slope), xlabel = 'x')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTJxPo1jFJLA"
   },
   "source": [
    " \n",
    "**Before executing next cell** Guess the correlation coefficient for each of these 9 plots and draw a plot of those correlation coefficients vs the slope (so y axis is correlation coefficient and x axis is slope). Note that this graph won't be graded on accuracy but you will be expected to submit it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYffPA0kGVyt"
   },
   "source": [
    "### **Answer**\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "Put your graph here\n",
    "</font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " AFTER PREVIOUS STEP: Execute this cell to plot correlation coefficients vs slope\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4xRWDyAwE0bw",
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown AFTER PREVIOUS STEP: Execute this cell to plot correlation coefficients vs slope\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.plot(slopes, corr_coefs, 'o-', c='#70E0BD', lw=3)\n",
    "\n",
    "ax.set(title='Correlation coefficient vs slope', xlabel='Slope', ylabel='Corr coeff');"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgBubUOPFkHP"
   },
   "source": [
    "Does this graph look different than the one you had predicted? If so, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QszWe2m_GX2d"
   },
   "source": [
    "### **Answer**\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "Text answer here\n",
    "</font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVfcHP0C6QiO"
   },
   "source": [
    "## C) Variable relationships with zero correlation\n",
    "\n",
    "Draw a scatter plot of x and y where there is a clear relationship between them but they would have a correlation coefficient of 0. You can draw this by hand or make the data points and plot in matplotlib (the added benefit being you can check the correlation is almost 0). \n",
    "\n",
    "**Why would your x/ys have a correlation coefficient of 0?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVKqetIhGY6L"
   },
   "source": [
    "### **Answer**\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "Put your graph here\n",
    "</font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSTxqAmJGcOs"
   },
   "source": [
    "### **Answer**\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "Text answer here\n",
    "</font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBeiKKG_Gim2"
   },
   "source": [
    "**Extra info**\n",
    "\n",
    "Another common misunderstanding is between correlation and causation. Even if x and y have a correlation of 1, we cannot say that one causes the other. There could be other additional factors that lead to x and y being highly correlated without being causal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbpT7zDI7PmA"
   },
   "source": [
    "# Exercise 2: Decoding head direction\n",
    "\n",
    "In this exercise we will again use the neural responses to head direction we outlined in Week 6 Tutorial 1. \n",
    "\n",
    "Let's say we just the neural response (spike count) and want to guess the head direction that the mouse is at. This is called decoding. In decoding generally, we are trying to reconstruct some stimulus or behavior from the neural responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cx45wQQR7dC2"
   },
   "source": [
    "## A) Maximizing likelihood estimator\n",
    "\n",
    "If we know the probability of the spike count given the head direction, one option is to guess the the head direction that maximizes that probability. We do know this probability mapping - it's our Poisson distribution from Exercise 1. In particular, $P(S = k | H = \\theta)$ is our likelihood: the probability of spike count k given the head direction at that point in time, or $\\theta$ .\n",
    "\n",
    "$$ P(S = k | H = \\theta) = \\frac{\\lambda ^k e^{-\\lambda}}{k!} $$ where $\\lambda = \\frac{1}{20}\\theta$.\n",
    "\n",
    "\n",
    "**If our spike count is 15, what is your guess of $\\theta$ given this spike count?** \n",
    "\n",
    "Let's solve this using a brute force coding method: loop over possible $\\theta s$, compute $P(S = k | H = \\theta)$ for each, and then find which $\\theta$ maximizes that quantity. \n",
    "\n",
    "You may want to use `np.math.factorial`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Kgro4Vv97ef7"
   },
   "source": [
    "thetas = np.arange(0, 360, 1)\n",
    "\n",
    "k = 15\n",
    "likelihoods = np.zeros((len(thetas),))\n",
    "for i, theta in enumerate(thetas):\n",
    "  ...\n",
    "\n",
    "# Get theta that maximizes the likelihood\n",
    "theta_max_likelihood = ...\n",
    "print(theta_max_likelihood)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_MlJESem7hAS"
   },
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(thetas, likelihoods, 'k')\n",
    "ax.set(xlabel='Theta', ylabel='P(S= 15 | H=theta)');"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUvO537y7kFX"
   },
   "source": [
    "### **Answer**\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "Answer here\n",
    "</font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1i6GtosE7ieE"
   },
   "source": [
    "## B) Incorporating priors\n",
    "\n",
    "We notice however that the mouse spends much more time in certain head directions than others. In particular, the mouse spends a lot of time facing forward, which is at $\\theta=0$. We get the probability that the mouse is at each $\\theta$ by computing the fraction of time she spends at that head direction. I give this to you below (`prior_prob`) - see plot below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Execute this cell to get and visualize prior_prob \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5SDSDQHe7m_m",
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Execute this cell to get and visualize prior_prob \n",
    "\n",
    "import scipy.signal\n",
    "\n",
    "gauss = scipy.signal.gaussian(360, 50, sym=True)+1\n",
    "gauss /= np.sum(gauss)\n",
    "prior_prob = np.concatenate((gauss[int(360/2):], gauss[:int(360/2)]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(thetas, prior_prob, 'k')\n",
    "ax.set(xlabel='Theta', ylabel='P(H=theta)');"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxGscYC57rHa"
   },
   "source": [
    "We think we can get a more accurate guess of head direction given the spike count of 15  by incorporating the additional information of how likely the mouse is to be at each head direction (our prior on head direction). \n",
    "\n",
    "Luckily, we have a nice way to do this using Bayes Theorem! In particular, \n",
    "\n",
    "$$ P(H = \\theta | S = k) = \\frac{P(S=k|H=\\theta)P(H=\\theta)}{P(S=k)}$$\n",
    "\n",
    "We now want to guess the head direction that lead to a spike count of 15 by maximing $P(H = \\theta | S = k)$, our posterior, instead of $P(S = k | H = \\theta)$, our likelihood. We can drop the denominator $P(S=k)$ because this is constant across head directions so won't affect our guess. \n",
    "\n",
    "$$ P(H = \\theta | S = k) \\propto P(S=k|H=\\theta)P(H=\\theta)$$\n",
    "**What $\\theta$ would we guess the mouse is at if we maximize $P(H = \\theta | S = k)$?**\n",
    "\n",
    "We can again use the brute force method."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "24hkGKqi7rS6"
   },
   "source": [
    "k = 15\n",
    "posterior_probs = np.zeros((len(thetas),))\n",
    "for i, theta in enumerate(thetas):\n",
    "  ...\n",
    "\n",
    "\n",
    "# Get theta that maximizes the posterior probability\n",
    "theta_max_posterior = ...\n",
    "print(theta_max_posterior)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dhaSe3-K7vQa"
   },
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(thetas, posterior_probs, 'k')\n",
    "ax.set(xlabel='Theta', ylabel='Proportional to P(H=theta | S= 15)');"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZ9EqyAL7uNx"
   },
   "source": [
    "### **Answer**\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "Answer here\n",
    "</font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYguL7CB7yAo"
   },
   "source": [
    "## C) Comparison\n",
    "\n",
    "Compare the guess of $\\theta$ in A vs B. Why does it make sense that the difference is what it is? Aka, how and why did the prior over head direction effect the guess the way it did?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrIcdiRW72Fp"
   },
   "source": [
    "### **Answer**\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "Answer here\n",
    "</font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHiWJmD48C-B"
   },
   "source": [
    "# Exercise 3: MLE Derivation for Binomial Distribution\n",
    "\n",
    "We can model a single coin flip using the Bernoulli distribution:\n",
    "$$ P( k | p ) = p^k (1-p)^{1-k} $$\n",
    "\n",
    "where p is the probability of the coin coming up heads and k indicates heads vs tails (k = 1 is heads, k = 0 is tails).\n",
    "\n",
    "We can model a series of coin flips using the binomial distribution; we obtain a binomial distribution by summing up n independent Bernoulli random variables Ber(p), each of which has probability p of coming up heads. A binomial distribution is:\n",
    "\n",
    "$$ p( k | n, p) = \\binom{n}{k}p^k (1-p)^{n-k} $$\n",
    "\n",
    "where $\\binom{n}{k}$ is a binomial coefficient (n choose k) equal to $\\frac{n!}{k!(n-k)!}$. This counts the number of different ways you can get k heads from n flipped coins and is essentially there to make the distribution sum to 1.\n",
    "Let's derive the equation for the maximum likelihood estimator for p in a binomial distribution.\n",
    "\n",
    "Show your work!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjdOkDsB9qRd"
   },
   "source": [
    "### **Answer**\n",
    "<font color='green'><span style=\"font-size:larger;\">\n",
    "Answer here\n",
    "</font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Major hint\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mcjUgsNP8GUq",
    "cellView": "form",
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# @markdown Major hint\n",
    "\n",
    "# Take the derivative of the log likelihood and\n",
    "# set equal to 0"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}