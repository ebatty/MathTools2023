
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Tutorial 1 &#8212; Mathematical Tools for Neuroscientists</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="(Optional) Tutorial 2" href="Week8Tutorial2.html" />
    <link rel="prev" title="Video 8.2: Statistical encoding models" href="Video82.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Mathematical Tools for Neuroscientists</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Linear Algebra &amp; Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week1/Overview.html">
   Week 1: Vectors
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Video11.html">
     Video 1.1: What is a vector?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Video12.html">
     Video 1.2: Vector properties &amp; operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Video13.html">
     Video 1.3: Vector spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Week1Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Week1Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week2/Overview.html">
   Week 2: Matrices
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video21.html">
     Video 2.1: Linear transformations and matrices (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video22.html">
     Video 2.2: Matrix multiplication as composition(3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video23.html">
     Video 2.3: The determinant (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video24.html">
     Video 2.4: Inverse matrices, column space, and null space (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video25.html">
     Video 2.5: Nonsquare matrices as transformations between dimensions (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Week2Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Week2Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week3/Overview.html">
   Week 3: Discrete Dynamics &amp; Eigenstuff
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Video31.html">
     Video 3.1: Intro to Dynamical Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Video32.html">
     Video 3.2: Discrete Dynamical Neural Circuit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Video33.html">
     Video 3.3: Eigenvalues and eigenvectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Week3Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Week3Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week4/Overview.html">
   Week 4: Continuous Dynamical Systems &amp; Differential Equations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/KeyConcepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video41.html">
     Video 4.1: Eigenvalues &amp; Discrete Dynamical Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video42.html">
     Video 4.2: Review of Differentiation &amp; Integration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video43.html">
     Video 4.3: Solving differential equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video44.html">
     Video 4.4: Systems of differential equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Week4Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Week4Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week5/Overview.html">
   Week 5: Matrix Decomposition &amp; Dimensionality Reduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week5/Video51.html">
     Video 5.1: Special Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week5/Video52.html">
     Video 5.2: Matrix Decomposition &amp; SVD
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week5/Video53.html">
     Video 5.3: PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week5/Week5Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week5/Week5Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../LinearAlgebraReview/Overview.html">
   Review
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../LinearAlgebraReview/MathTools_Homework1.html">
     Homework 1
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probability &amp; Statistics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week6/Overview.html">
   Week 6: Intro to Probability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week6/KeyConcepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week6/Reading61.html">
     Reading 6.1: Intro to Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week6/Week6Tutorial1.html">
     Tutorial 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week7/Overview.html">
   Week 7: Intro to Statistics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video71.html">
     Video 7.1: Descriptive Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video72.html">
     Video 7.2: Overview of Statistical Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video73.html">
     Video 7.3: Point Estimators Examples &amp; Goodness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video74.html">
     Video 7.4: Maximum Likelihood Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video75.html">
     Video 7.5: Bayesian Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Week7Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Week7Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="Overview.html">
   Week 8: Statistical Encoding &amp; Decoding
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="Video81.html">
     Video 8.1: What are encoding &amp; decoding?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Video82.html">
     Video 8.2: Statistical encoding models
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week8Tutorial2.html">
     (Optional) Tutorial 2
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week9/Overview.html">
   Week 9: Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Video91.html">
     Video 9.1: What is machine learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Video92.html">
     Video 9.2: Types of machine learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Video93.html">
     Video 9.3: Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Week9Tutorial1.html">
     Tutorial 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week10/Overview.html">
   Week 10: Model Selection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/Video101.html">
     Video 10.1: Model evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/Video102.html">
     Video 10.2: Bootstrapping (NMA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/Video103.html">
     Video 10.3: Model selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/Week10Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week10/Week10Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week11/Overview.html">
   Week 11: Clustering &amp; Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Video111.html">
     Video 11.1: Clustering Applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Video112.html">
     Video 11.2: Types of Clustering Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Video113.html">
     Video 11.3: K-Means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Week11Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Week11Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week12/Overview.html">
   Week 12: Deep Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video121.html">
     Video 12.1: Feedforward networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video122.html">
     Video 12.2: Training Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video123.html">
     Video 12.3: Practical steps for training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video124.html">
     Reaching 12.4: Intro to Pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Week12Tutorial1.html">
     Tutorial 1
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://colab.research.google.com/github/ebatty/MathToolsforNeuroscience/blob/jupyterbook/Week8/Week8Tutorial1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/Week8/Week8Tutorial1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-data">
   The data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-1-computing-an-sta">
   Exercise 1: Computing an STA
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#answer">
     Answer
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optional-exercise-estimate-the-nonlinearity">
   (Optional) Exercise: Estimate the nonlinearity
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-2-numerically-finding-the-filter-with-natural-scenes-data">
   Exercise 2: Numerically finding the filter with natural scenes data
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-negative-log-likelihood-equation">
     A) Negative log likelihood equation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       <strong>
        Answer
       </strong>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-negative-log-likelihood-computation">
     B) Negative log likelihood computation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#c-compute-dnll-dk">
     C) Compute dNLL/dk
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       <strong>
        Answer
       </strong>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#d-implementing-gradient-descent">
     D) Implementing gradient descent
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#e-larger-steps">
     E) Larger steps
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       <strong>
        Answer
       </strong>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extra-info">
     Extra info
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Tutorial 1</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-data">
   The data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-1-computing-an-sta">
   Exercise 1: Computing an STA
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#answer">
     Answer
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optional-exercise-estimate-the-nonlinearity">
   (Optional) Exercise: Estimate the nonlinearity
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-2-numerically-finding-the-filter-with-natural-scenes-data">
   Exercise 2: Numerically finding the filter with natural scenes data
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-negative-log-likelihood-equation">
     A) Negative log likelihood equation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       <strong>
        Answer
       </strong>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-negative-log-likelihood-computation">
     B) Negative log likelihood computation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#c-compute-dnll-dk">
     C) Compute dNLL/dk
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       <strong>
        Answer
       </strong>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#d-implementing-gradient-descent">
     D) Implementing gradient descent
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#e-larger-steps">
     E) Larger steps
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id5">
       <strong>
        Answer
       </strong>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#extra-info">
     Extra info
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p><a href="https://colab.research.google.com/github/ebatty/MathToolsforNeuroscience/blob/jupyterbook/Week8/Week8Tutorial1.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-1">
<h1>Tutorial 1<a class="headerlink" href="#tutorial-1" title="Permalink to this headline">#</a></h1>
<p><strong>Probability &amp; Statistics III: Statistical Encoding &amp; Decoding</strong></p>
<p><strong>[insert your name]</strong></p>
<p><strong>Important reminders</strong>: Before starting, click “File -&gt; Save a copy in Drive”. Produce a pdf for submission by “File -&gt; Print” and then choose “Save to PDF”.</p>
<p>To complete this tutorial, you should have watched Video 8.1 and 8.2.</p>
<p>Imports</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Imports

# Imports
import numpy as np
import matplotlib.pyplot as plt
import ipywidgets as widgets  # interactive display
import math
</pre></div>
</div>
</div>
</div>
<p>Plotting functions</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Plotting functions
import numpy
from numpy.linalg import inv, eig
from math import ceil
from matplotlib import pyplot, ticker, get_backend, rc
from mpl_toolkits.mplot3d import Axes3D
from itertools import cycle


%config InlineBackend.figure_format = &#39;retina&#39;
plt.style.use(&quot;https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle&quot;)
</pre></div>
</div>
</div>
</div>
<p>Helper functions</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Helper functions
def twoD_Gaussian(xdata_tuple, amplitude, xo, yo, sigma_x, sigma_y, theta, offset):
  &quot;&quot;&quot;Create 2D Gaussian based on parameters

  Args:
    xdata_tuple (ndarray): grid of x and y values to compute Gaussian for
    amplitude (scalar): amplitude of Gaussian
    xo (scalar): center of Gaussian in x coordinates
    yo (scalar): center of Gaussian in y coordinates
    sigma_x (scalar): standard deviation of Gaussian in x direction
    sigma_y (scalar): standard deviation of Gaussian in y direction
    theta (scalar): rotation angle of Gaussian
    offset (scalar): offset of all Gaussian values

  Returns:
    ndarray: Gaussian values at every x/y point

  &quot;&quot;&quot;
  (x, y) = xdata_tuple
  xo = float(xo)
  yo = float(yo)    
  a = (np.cos(theta)**2)/(2*sigma_x**2) + (np.sin(theta)**2)/(2*sigma_y**2)
  b = -(np.sin(2*theta))/(4*sigma_x**2) + (np.sin(2*theta))/(4*sigma_y**2)
  c = (np.sin(theta)**2)/(2*sigma_x**2) + (np.cos(theta)**2)/(2*sigma_y**2)
  g = offset + amplitude*np.exp( - (a*((x-xo)**2) + 2*b*(x-xo)*(y-yo)+c*((y-yo)**2)))
  return g.ravel()
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="the-data">
<h1>The data<a class="headerlink" href="#the-data" title="Permalink to this headline">#</a></h1>
<p>In this tutorial, we will be working with simulated neural data from a visual neuron in response to Gaussian white noise and MNIST images (we’ll call these natural scenes for ease even though they aren’t very natural). We will be fitting LNP models for both types of stimuli separately. We have 10000 images for each type of stimuli and each image is 10 x 10 pixels.</p>
<p>The next cell gives you <code class="docutils literal notranslate"><span class="pre">WN_images</span></code> and <code class="docutils literal notranslate"><span class="pre">NS_images</span></code>, the white noise and MNIST images respectively. Each is 10000 x 100 so the images have already been vectorized.</p>
<p>Execute this cell to get and visualize example image of each type (may take a few min to download)</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute this cell to get and visualize example image of each type (may take a few min to download)

np.random.seed(123)
n_images = 10000

# Get WN images
WN_images = np.random.randn(n_images, 10*10)

# Get NS images
from sklearn.datasets import fetch_openml
mnist = fetch_openml(name=&#39;mnist_784&#39;)
mnist_images = np.array(mnist.data)
mnist_images = mnist_images/255 
mnist_images = mnist_images - np.mean(mnist_images)

mnist_images = mnist_images.reshape((-1, 28, 28))[:, 4:24, 4:24]
mnist_images = mnist_images[:, ::2, ::2]
NS_images = mnist_images[:n_images].reshape((-1, 10*10))

fig, axes = plt.subplots(1, 2, figsize=(10, 5))
axes[0].imshow(WN_images[0].reshape((10, 10)), vmin=-1, vmax=1, cmap=&#39;gray&#39;)
axes[1].imshow(NS_images[0].reshape((10, 10)), vmin=-1, vmax=1, cmap=&#39;gray&#39;)
axes[0].axis(&#39;Off&#39;)
axes[1].axis(&#39;Off&#39;)
axes[0].set(title=&#39;WN example image&#39;)
axes[1].set(title=&#39;NS example image&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">line</span> <span class="mi">10</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="n">WN_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_images</span><span class="p">,</span> <span class="mi">10</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="c1"># Get NS images</span>
<span class="ne">---&gt; </span><span class="mi">10</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span> <span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="n">mnist_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;sklearn&#39;
</pre></div>
</div>
</div>
</div>
<p>The response to each image is a summed spike count response so we do not have to worry about accounting for the time lags of the stimuli etc. We are simulating the neuron as an LNP model with an exponential nonlinearity so a linear filter, then exponential, then Poisson draws. Note that this means our LNP fits will be really good because we are using the correct model (this will literally never happen in real life…)</p>
<p>Execute the next cell to simulate our neuron and get <code class="docutils literal notranslate"><span class="pre">WN_spike_counts</span></code> and <code class="docutils literal notranslate"><span class="pre">NS_spike_counts</span></code>. <code class="docutils literal notranslate"><span class="pre">filter</span></code> is the true linear filter of this neuron.</p>
<p>Execute to simulate neural responses</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute to simulate neural responses
np.random.seed(0)

x = np.arange(-5, 5, 1)
y = np.arange(-5, 5, 1)
x, y = np.meshgrid(x, y)

sd_x = 1.4
sd_y = .5
gauss = twoD_Gaussian((x,y), 1, 0, 0, sd_x, sd_y, 35, 0)
filter = gauss.reshape((10, 10))

WN_lambda = np.exp(np.dot(WN_images, filter.reshape((-1,))))
WN_spike_counts = np.random.poisson(WN_lambda)

NS_lambda = np.exp(np.dot(NS_images, filter.reshape((-1,))))
NS_spike_counts = np.random.poisson(NS_lambda)

fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharex=True)
axes[0].plot(WN_spike_counts[0:100], &#39;ok&#39;)
axes[1].plot(NS_spike_counts[0:100], &#39;ok&#39;)
axes[0].set(ylabel=&#39;Spike counts&#39;, xlabel=&#39;Image number&#39;, title=&#39;WN&#39;)
axes[1].set(xlabel=&#39;Image number&#39;, title=&#39;NS&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">line</span> <span class="mi">16</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span> <span class="n">WN_lambda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">WN_images</span><span class="p">,</span> <span class="nb">filter</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,))))</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="n">WN_spike_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">WN_lambda</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">16</span> <span class="n">NS_lambda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">NS_images</span><span class="p">,</span> <span class="nb">filter</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,))))</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="n">NS_spike_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">NS_lambda</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;NS_images&#39; is not defined
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-1-computing-an-sta">
<h1>Exercise 1: Computing an STA<a class="headerlink" href="#exercise-1-computing-an-sta" title="Permalink to this headline">#</a></h1>
<p>We want to fit an LNP model for each type of stimulus. Since our white noise is stochastic and spherically distributed, we know we can compute a spike triggered average and it will be an unbiased estimator for our linear filter. In fact, we will assume an exponential nonlinearity so it will be the maximum likelihood estimator for our linear filter.</p>
<p>Fill out the code below to create a function that computes the STA from a set of images and associated spike counts. Compute this STA for both white noise and natural scenes. Run the next cell to visualize your computed STAs next to the original (true) linear filter.</p>
<section id="answer">
<h2>Answer<a class="headerlink" href="#answer" title="Permalink to this headline">#</a></h2>
<p>Fill out code below</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>WN_spike_counts.shape
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(10000,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def compute_STA(images, spike_counts):

  STA = ...

  return STA


WN_STA = ...
NS_STA = ...
</pre></div>
</div>
</div>
</div>
<p>Execute to visualize your computed STAs and the original filter</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute to visualize your computed STAs and the original filter

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

axes[0].imshow(filter.reshape((10, 10)), vmin=-1, vmax=1, cmap=&#39;gray&#39;)
axes[1].imshow(WN_STA.reshape((10, 10)), vmin=-1, vmax=1, cmap=&#39;gray&#39;)
axes[2].imshow(NS_STA.reshape((10, 10)), vmin=-1, vmax=1, cmap=&#39;gray&#39;)

for i in range(3):
  axes[i].axis(&#39;Off&#39;)

axes[0].set(title=&#39;True filter&#39;)
axes[1].set(title=&#39;White noise STA&#39;)
axes[2].set(title=&#39;Natural scenes STA&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AttributeError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">line</span> <span class="mi">6</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="nb">filter</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">6</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">WN_STA</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">NS_STA</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>

<span class="ne">AttributeError</span>: &#39;ellipsis&#39; object has no attribute &#39;reshape&#39;
</pre></div>
</div>
<img alt="../_images/Week8Tutorial1_19_1.png" src="../_images/Week8Tutorial1_19_1.png" />
</div>
</div>
<p>Note that the white noise STA is a pretty good estimate for the true filter, but the natural scenes STA is not!</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="optional-exercise-estimate-the-nonlinearity">
<h1>(Optional) Exercise: Estimate the nonlinearity<a class="headerlink" href="#optional-exercise-estimate-the-nonlinearity" title="Permalink to this headline">#</a></h1>
<p>Estimate the nonlinearity of the LNP model (so no longer predefine it as exponential) using the method discussed in Video 8.2.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-2-numerically-finding-the-filter-with-natural-scenes-data">
<h1>Exercise 2: Numerically finding the filter with natural scenes data<a class="headerlink" href="#exercise-2-numerically-finding-the-filter-with-natural-scenes-data" title="Permalink to this headline">#</a></h1>
<p>The STA was a very convenient estimate of our linear filter of an LNP model for the white noise stimuli. Unfortunately, it is a bad estimator for the natural scenes stimuli so we will have to use a numerical approach to estimate the filter using this data. In this exercise, we will implement gradient descent ourselves.</p>
<section id="a-negative-log-likelihood-equation">
<h2>A) Negative log likelihood equation<a class="headerlink" href="#a-negative-log-likelihood-equation" title="Permalink to this headline">#</a></h2>
<p>To implement gradient descent ourselves, we will need to compute the derivative of the negative log likelihood.</p>
<p>Write out the negative log likelihood equation for our LNP model with an exponential nonlinearity. Simplify as much as possible. Drop constants that don’t depend on the filter (so we won’t compute the true NLL but the relative NLL for different filters). Show the math! Use y for the spike counts and x for the images.</p>
<p>Make the final equation clear either with the green text below or by putting it in a box or otherwise highlighting it.</p>
<section id="id1">
<h3><strong>Answer</strong><a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p><font color='green'><span style="font-size:larger;">
Put NLL = … equation here (show work above or below)
</font> </span></p>
</section>
</section>
<section id="b-negative-log-likelihood-computation">
<h2>B) Negative log likelihood computation<a class="headerlink" href="#b-negative-log-likelihood-computation" title="Permalink to this headline">#</a></h2>
<p>Use your equation in part A to fill out the code below to compute the negative log likelihood for a given filter (k) and set of images (x) and spike counts (y). x and y would be the same shape as WN_images and WN_spike_counts for example</p>
<section id="id2">
<h3>Answer<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<p>Fill out code below</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def compute_NLL(k, x, y):

    NLL = ...
    
    return NLL

fake_k = np.zeros((100,))
NLL = compute_NLL(fake_k, WN_images, WN_spike_counts)
print(NLL)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ellipsis
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="c-compute-dnll-dk">
<h2>C) Compute dNLL/dk<a class="headerlink" href="#c-compute-dnll-dk" title="Permalink to this headline">#</a></h2>
<p>Take your answer in part A and now take the derivative with respect to <span class="math notranslate nohighlight">\(\bar{k}\)</span>. Note that <span class="math notranslate nohighlight">\(\bar{k}\)</span> is a vector so this can get tricky! I would take the derivative with respect to <span class="math notranslate nohighlight">\(\bar{k}_o\)</span> first (the first element of <span class="math notranslate nohighlight">\(k\)</span>). Since each entry of <span class="math notranslate nohighlight">\(\bar{k}\)</span> is present in the negative log likelihood equation in a similar manner, you should be able to extend your calculation for <span class="math notranslate nohighlight">\(\frac{dNLL}{d\bar{k}_0}\)</span> to figure out the whole vector <span class="math notranslate nohighlight">\(\frac{dNLL}{d\bar{k}}\)</span>.</p>
<p>When in confusion about dot products, my recommendation is to write out the first few elements of the dot product computation for clarifiation.</p>
<p>Make the final equation clear either with the green text below or by putting it in a box or otherwise highlighting it. Show your work!</p>
<section id="id3">
<h3><strong>Answer</strong><a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h3>
<p><font color='green'><span style="font-size:larger;">
Put dNLL/dk = … equation here (show work above or below)
</font> </span></p>
</section>
</section>
<section id="d-implementing-gradient-descent">
<h2>D) Implementing gradient descent<a class="headerlink" href="#d-implementing-gradient-descent" title="Permalink to this headline">#</a></h2>
<p>We now have all the tools we need to implement gradient descent to find an estimate of our filter k using the natural scenes data.</p>
<p>Fill out the following code to perform gradient descent and then call it for the natural scenes data. The following cells plot the loss function (negative log likelihood) over step of the gradient descent algorithm and the fitted filter.</p>
<section id="id4">
<h3>Answer<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h3>
<p>Fill out code below</p>
<p>Execute to visualize negative log likelihood over gradient descent</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def gradient_descent(x, y, init_guess, n_steps = 500, alpha=10**-6):

    k = init_guess
    NLL = np.zeros((n_steps,))
    for i_step in range(n_steps):

      # Update estimate of k (assign as k)
      # your code here

      # Compute NLL at each step
      NLL[i_step] = compute_NLL(k, x, y)

    return k, NLL

k, NLL = ...
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">line</span> <span class="mi">15</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>       <span class="n">NLL</span><span class="p">[</span><span class="n">i_step</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_NLL</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span>     <span class="k">return</span> <span class="n">k</span><span class="p">,</span> <span class="n">NLL</span>
<span class="ne">---&gt; </span><span class="mi">15</span> <span class="n">k</span><span class="p">,</span> <span class="n">NLL</span> <span class="o">=</span> <span class="o">...</span>

<span class="ne">TypeError</span>: cannot unpack non-iterable ellipsis object
</pre></div>
</div>
</div>
</div>
<p>Execute to visualize your estimated filter</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute to visualize negative log likelihood over gradient descent
fig, axes = plt.subplots()
axes.plot(NLL,&#39;-ok&#39;)
axes.set(ylabel=&#39;NLL&#39;, xlabel=&#39;Gradient descent step&#39;, title=&#39;LNP fitting&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">11</span><span class="p">],</span> <span class="n">line</span> <span class="mi">3</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># @markdown Execute to visualize negative log likelihood over gradient descent</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="n">axes</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">NLL</span><span class="p">,</span><span class="s1">&#39;-ok&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">axes</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;NLL&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;Gradient descent step&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;LNP fitting&#39;</span><span class="p">);</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1664,</span> in <span class="ni">Axes.plot</span><span class="nt">(self, scalex, scaley, data, *args, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1662</span> <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_lines</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)]</span>
<span class="g g-Whitespace">   </span><span class="mi">1663</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1664</span>     <span class="bp">self</span><span class="o">.</span><span class="n">add_line</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1665</span> <span class="k">if</span> <span class="n">scalex</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1666</span>     <span class="bp">self</span><span class="o">.</span><span class="n">_request_autoscale_view</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/matplotlib/axes/_base.py:2340,</span> in <span class="ni">_AxesBase.add_line</span><span class="nt">(self, line)</span>
<span class="g g-Whitespace">   </span><span class="mi">2337</span> <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">get_clip_path</span><span class="p">()</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">2338</span>     <span class="n">line</span><span class="o">.</span><span class="n">set_clip_path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">patch</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">2340</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_line_limits</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">2341</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">line</span><span class="o">.</span><span class="n">get_label</span><span class="p">():</span>
<span class="g g-Whitespace">   </span><span class="mi">2342</span>     <span class="n">line</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;_child</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/matplotlib/axes/_base.py:2363,</span> in <span class="ni">_AxesBase._update_line_limits</span><span class="nt">(self, line)</span>
<span class="g g-Whitespace">   </span><span class="mi">2359</span> <span class="k">def</span> <span class="nf">_update_line_limits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">line</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">2360</span>     <span class="sd">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">2361</span><span class="sd">     Figures out the data limit of the given line, updating self.dataLim.</span>
<span class="g g-Whitespace">   </span><span class="mi">2362</span><span class="sd">     &quot;&quot;&quot;</span>
<span class="ne">-&gt; </span><span class="mi">2363</span>     <span class="n">path</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">get_path</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">2364</span>     <span class="k">if</span> <span class="n">path</span><span class="o">.</span><span class="n">vertices</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">2365</span>         <span class="k">return</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/matplotlib/lines.py:1031,</span> in <span class="ni">Line2D.get_path</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1029</span> <span class="sd">&quot;&quot;&quot;Return the `~matplotlib.path.Path` associated with this line.&quot;&quot;&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1030</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_invalidy</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_invalidx</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1031</span>     <span class="bp">self</span><span class="o">.</span><span class="n">recache</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1032</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_path</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/matplotlib/lines.py:664,</span> in <span class="ni">Line2D.recache</span><span class="nt">(self, always)</span>
<span class="g g-Whitespace">    </span><span class="mi">662</span> <span class="k">if</span> <span class="n">always</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_invalidy</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">663</span>     <span class="n">yconv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_yunits</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_yorig</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">664</span>     <span class="n">y</span> <span class="o">=</span> <span class="n">_to_unmasked_float_array</span><span class="p">(</span><span class="n">yconv</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">665</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">666</span>     <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y</span>

<span class="nn">File /opt/hostedtoolcache/Python/3.8.14/x64/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1369,</span> in <span class="ni">_to_unmasked_float_array</span><span class="nt">(x)</span>
<span class="g g-Whitespace">   </span><span class="mi">1367</span>     <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">filled</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1368</span> <span class="k">else</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1369</span>     <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

<span class="ne">TypeError</span>: float() argument must be a string or a number, not &#39;ellipsis&#39;
</pre></div>
</div>
<img alt="../_images/Week8Tutorial1_36_1.png" src="../_images/Week8Tutorial1_36_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute to visualize your estimated filter

fig, axes = plt.subplots(1, 2, figsize=(10, 5))

axes[0].imshow(filter.reshape((10, 10)), vmin=-1, vmax=1, cmap=&#39;gray&#39;)
axes[1].imshow(k.reshape((10, 10)), vmin=-1, vmax=1, cmap=&#39;gray&#39;)

for i in range(2):
  axes[i].axis(&#39;Off&#39;)

axes[0].set(title=&#39;True filter&#39;)
axes[1].set(title=&#39;Estimate of k using NS data&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">12</span><span class="p">],</span> <span class="n">line</span> <span class="mi">6</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="nb">filter</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">6</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span>   <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;Off&#39;</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;k&#39; is not defined
</pre></div>
</div>
<img alt="../_images/Week8Tutorial1_37_1.png" src="../_images/Week8Tutorial1_37_1.png" />
</div>
</div>
</section>
</section>
<section id="e-larger-steps">
<h2>E) Larger steps<a class="headerlink" href="#e-larger-steps" title="Permalink to this headline">#</a></h2>
<p>In the next cell, try out performing gradient descent using your function above and step size alpha = <span class="math notranslate nohighlight">\(10^{-5}\)</span> instead of <span class="math notranslate nohighlight">\(10^{-6}\)</span>. What happens with the negative log likelihood over time? Why is this happening?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>k, NLL = ...

fig, axes = plt.subplots()
axes.plot(NLL,&#39;-ok&#39;)
axes.set(ylabel=&#39;NLL&#39;, xlabel=&#39;Gradient descent step&#39;, title=&#39;LNP fitting&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">13</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">k</span><span class="p">,</span> <span class="n">NLL</span> <span class="o">=</span> <span class="o">...</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">axes</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">NLL</span><span class="p">,</span><span class="s1">&#39;-ok&#39;</span><span class="p">)</span>

<span class="ne">TypeError</span>: cannot unpack non-iterable ellipsis object
</pre></div>
</div>
</div>
</div>
<section id="id5">
<h3><strong>Answer</strong><a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h3>
<p><font color='green'><span style="font-size:larger;">
Text answer here
</font> </span></p>
</section>
</section>
<section id="extra-info">
<h2>Extra info<a class="headerlink" href="#extra-info" title="Permalink to this headline">#</a></h2>
<p>We didn’t need to compute gradient descent ourselves. We could have used an optimizer from scipy as shown in the following code. We computed our gradient by hand for practice and to really look “under the hood” of gradient descent.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from scipy.optimize import minimize
init_guess = np.zeros((10*10,))
outs = minimize(compute_NLL, init_guess, (NS_images, NS_spike_counts))


plt.imshow(outs.x.reshape((10, 10)), vmin=-1, vmax=1,cmap=&#39;gray&#39;)
plt.axis(&#39;Off&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">14</span><span class="p">],</span> <span class="n">line</span> <span class="mi">3</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">init_guess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="o">*</span><span class="mi">10</span><span class="p">,))</span>
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="n">outs</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">compute_NLL</span><span class="p">,</span> <span class="n">init_guess</span><span class="p">,</span> <span class="p">(</span><span class="n">NS_images</span><span class="p">,</span> <span class="n">NS_spike_counts</span><span class="p">))</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">outs</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;Off&#39;</span><span class="p">);</span>

<span class="ne">NameError</span>: name &#39;NS_images&#39; is not defined
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ebatty/MathToolsforNeuroscience",
            ref: "jupyterbook",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Week8"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Video82.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Video 8.2: Statistical encoding models</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Week8Tutorial2.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">(Optional) Tutorial 2</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ella Batty<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>