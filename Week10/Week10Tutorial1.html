
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Tutorial 1 &#8212; Mathematical Tools for Neuroscientists</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tutorial 2" href="Week10Tutorial2.html" />
    <link rel="prev" title="Video 10.3: Model selection" href="Video103.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Mathematical Tools for Neuroscientists</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Linear Algebra &amp; Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week1/Overview.html">
   Week 1: Vectors
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Video11.html">
     Video 1.1: What is a vector?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Video12.html">
     Video 1.2: Vector properties &amp; operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Video13.html">
     Video 1.3: Vector spaces
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Week1Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week1/Week1Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week2/Overview.html">
   Week 2: Matrices
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video21.html">
     Video 2.1: Linear transformations and matrices (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video22.html">
     Video 2.2: Matrix multiplication as composition(3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video23.html">
     Video 2.3: The determinant (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video24.html">
     Video 2.4: Inverse matrices, column space, and null space (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Video25.html">
     Video 2.5: Nonsquare matrices as transformations between dimensions (3Blue1Brown)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Week2Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week2/Week2Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week3/Overview.html">
   Week 3: Discrete Dynamics &amp; Eigenstuff
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Video31.html">
     Video 3.1: Intro to Dynamical Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Video32.html">
     Video 3.2: Discrete Dynamical Neural Circuit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Video33.html">
     Video 3.3: Eigenvalues and eigenvectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Week3Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week3/Week3Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week4/Overview.html">
   Week 4: Continuous Dynamical Systems &amp; Differential Equations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/KeyConcepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video41.html">
     Video 4.1: Eigenvalues &amp; Discrete Dynamical Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video42.html">
     Video 4.2: Review of Differentiation &amp; Integration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video43.html">
     Video 4.3: Solving differential equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Video44.html">
     Video 4.4: Systems of differential equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Week4Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week4/Week4Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week5/Overview.html">
   Week 5: Matrix Decomposition &amp; Dimensionality Reduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week5/Video51.html">
     Video 5.1: Special Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week5/Video52.html">
     Video 5.2: Matrix Decomposition &amp; SVD
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week5/Video53.html">
     Video 5.3: PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week5/Week5Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week5/Week5Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../LinearAlgebraReview/Overview.html">
   Review
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../LinearAlgebraReview/MathTools_Homework1.html">
     Homework 1
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Probability &amp; Statistics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week6/Overview.html">
   Week 6: Intro to Probability
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week6/KeyConcepts.html">
     Key Concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week6/Reading61.html">
     Reading 6.1: Intro to Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week6/Week6Tutorial1.html">
     Tutorial 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week7/Overview.html">
   Week 7: Intro to Statistics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video71.html">
     Video 7.1: Descriptive Statistics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video72.html">
     Video 7.2: Overview of Statistical Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video73.html">
     Video 7.3: Point Estimators Examples &amp; Goodness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video74.html">
     Video 7.4: Maximum Likelihood Estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Video75.html">
     Video 7.5: Bayesian Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Week7Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week7/Week7Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week8/Overview.html">
   Week 8: Statistical Encoding &amp; Decoding
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week8/Video81.html">
     Video 8.1: What are encoding &amp; decoding?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week8/Video82.html">
     Video 8.2: Statistical encoding models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week8/Week8Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week8/Week8Tutorial2.html">
     (Optional) Tutorial 2
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week9/Overview.html">
   Week 9: Linear Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Video91.html">
     Video 9.1: What is machine learning?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Video92.html">
     Video 9.2: Types of machine learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Video93.html">
     Video 9.3: Linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week9/Week9Tutorial1.html">
     Tutorial 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="Overview.html">
   Week 10: Model Selection
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="KeyConcepts.html">
     Key concepts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Video101.html">
     Video 10.1: Model evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Video102.html">
     Video 10.2: Bootstrapping (NMA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Video103.html">
     Video 10.3: Model selection
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Week10Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week11/Overview.html">
   Week 11: Clustering &amp; Classification
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Video111.html">
     Video 11.1: Clustering Applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Video112.html">
     Video 11.2: Types of Clustering Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Video113.html">
     Video 11.3: K-Means Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Week11Tutorial1.html">
     Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week11/Week11Tutorial2.html">
     Tutorial 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Week12/Overview.html">
   Week 12: Deep Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video121.html">
     Video 12.1: Feedforward networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video122.html">
     Video 12.2: Training Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video123.html">
     Video 12.3: Practical steps for training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Video124.html">
     Reaching 12.4: Intro to Pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Week12/Week12Tutorial1.html">
     Tutorial 1
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://colab.research.google.com/github/ebatty/MathToolsforNeuroscience/blob/jupyterbook/Week10/Week10Tutorial1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/Week10/Week10Tutorial1.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-1-polynomial-regression">
   Exercise 1: Polynomial regression
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-structuring-the-design-matrix">
     A) Structuring the design matrix
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#answer">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-coding-the-design-matrix">
     B) Coding the design matrix
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fitting-polynomial-regression-models">
     Fitting polynomial regression models
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-2-bias-variance-tradeoff">
   Exercise 2: Bias variance tradeoff
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-thinking-about-models">
     A) Thinking about models
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#looking-at-bias-vs-variance">
     Looking at bias vs variance
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#looking-at-train-vs-test-mse">
     Looking at train vs test MSE
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-3-model-selection-via-cross-validation">
   Exercise 3: Model selection via cross validation
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-by-hand-implementation-on-a-toy-example">
     A) By hand implementation on a toy example
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-using-sklearn">
     B) Using sklearn
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       Answer
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#coding-fun-everything-in-sklearn">
   Coding Fun: Everything in sklearn
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Tutorial 1</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-1-polynomial-regression">
   Exercise 1: Polynomial regression
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-structuring-the-design-matrix">
     A) Structuring the design matrix
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#answer">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-coding-the-design-matrix">
     B) Coding the design matrix
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fitting-polynomial-regression-models">
     Fitting polynomial regression models
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-2-bias-variance-tradeoff">
   Exercise 2: Bias variance tradeoff
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-thinking-about-models">
     A) Thinking about models
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#looking-at-bias-vs-variance">
     Looking at bias vs variance
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#looking-at-train-vs-test-mse">
     Looking at train vs test MSE
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-3-model-selection-via-cross-validation">
   Exercise 3: Model selection via cross validation
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-by-hand-implementation-on-a-toy-example">
     A) By hand implementation on a toy example
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       Answer
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-using-sklearn">
     B) Using sklearn
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       Answer
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#coding-fun-everything-in-sklearn">
   Coding Fun: Everything in sklearn
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p><a href="https://colab.research.google.com/github/ebatty/MathToolsforNeuroscience/blob/jupyterbook/Week10/Week10Tutorial1.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-1">
<h1>Tutorial 1<a class="headerlink" href="#tutorial-1" title="Permalink to this headline">#</a></h1>
<p><strong>Machine Learning II: Model Selection</strong></p>
<p><strong>[insert your name]</strong></p>
<p><strong>Important reminders</strong>: Before starting, click “File -&gt; Save a copy in Drive”. Produce a pdf for submission by “File -&gt; Print” and then choose “Save to PDF”.</p>
<p>To complete this tutorial, you should have watched Video 10.1, 10.2, and 10.3</p>
<p><strong>This tutorial is inspired by and uses text/code from NMA W1D3, which in turn was inspired by Eero Simoncelli’s Math Tools course</strong></p>
<p>Imports</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Imports

# Imports
import numpy as np
import matplotlib.pyplot as plt
import ipywidgets as widgets  # interactive display
import math
</pre></div>
</div>
</div>
</div>
<p>Plotting functions</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Plotting functions
import numpy
from numpy.linalg import inv, eig
from math import ceil
from matplotlib import pyplot, ticker, get_backend, rc
from mpl_toolkits.mplot3d import Axes3D
from itertools import cycle


%config InlineBackend.figure_format = &#39;retina&#39;
plt.style.use(&quot;https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle&quot;)

def plot_fitted_polynomials(x, y, theta_hat):
  &quot;&quot;&quot; Plot polynomials of different orders

  Args:
    x (ndarray): input vector of shape (n_samples)
    y (ndarray): vector of measurements of shape (n_samples)
    theta_hat (dict): polynomial regression weights for different orders
  &quot;&quot;&quot;

  x_grid = np.linspace(x.min() - .5, x.max() + .5)

  plt.figure()

  for order in range(0, max_order + 1):
    X_design = make_design_matrix(x_grid, order)
    plt.plot(x_grid, X_design @ theta_hat[order]);

  plt.ylabel(&#39;y&#39;)
  plt.xlabel(&#39;x&#39;)
  plt.plot(x, y, &#39;C0.&#39;);
  plt.legend([f&#39;order {o}&#39; for o in range(max_order + 1)], loc=1)
  plt.title(&#39;polynomial fits&#39;)
  plt.show()
</pre></div>
</div>
</div>
</div>
<p>Helper functions</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Helper functions

def ordinary_least_squares(X, y):
  &quot;&quot;&quot;Ordinary least squares estimator for linear regression.

  Args:
    x (ndarray): design matrix of shape (n_samples, n_regressors)
    y (ndarray): vector of measurements of shape (n_samples)

  Returns:
    ndarray: estimated parameter values of shape (n_regressors)
  &quot;&quot;&quot;
  
  # Compute theta_hat using OLS
  theta_hat = np.linalg.inv(X.T @ X) @ X.T @ y

  return theta_hat


def evaluate_poly_reg(x, y, theta_hat, order):
    &quot;&quot;&quot; Evaluates MSE of polynomial regression models on data

    Args:
      x (ndarray): input vector of shape (n_samples)
      y (ndarray): vector of measurements of shape (n_samples)
      theta_hats (dict):  fitted weights for each polynomial model (dict key is order)
      max_order (scalar): max order of polynomial fit

    Returns
      (ndarray): mean squared error for each order, shape (max_order)
    &quot;&quot;&quot;

    X_design = make_design_matrix(x, order)

    y_hat = np.dot(X_design, theta_hats[order])

    residuals = y - y_hat

    mse = np.mean(residuals ** 2)

    return mse
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-1-polynomial-regression">
<h1>Exercise 1: Polynomial regression<a class="headerlink" href="#exercise-1-polynomial-regression" title="Permalink to this headline">#</a></h1>
<p>We can extend linear regression to capture more complex nonlinear relationships by using polynomial regression.  Linear regression models predict the outputs as a weighted sum of the inputs:</p>
<div class="math notranslate nohighlight">
\[y_{n}= \theta_0 + \theta x_{n} + \epsilon_{n}\]</div>
<p>With polynomial regression, we model the outputs as a polynomial equation based on the inputs. For example, we can model the outputs as:</p>
<div class="math notranslate nohighlight">
\[y_{n}= \theta_0 + \theta_1 x_{n} + \theta_2 x_{n}^2 + \theta_3 x_{n}^3 + \epsilon_{n}\]</div>
<p>We can change how complex a polynomial is fit by changing the order of the polynomial. The order of a polynomial refers to the highest power in the polynomial. The equation above is a third order polynomial because the highest value x is raised to is 3. We could add another term (<span class="math notranslate nohighlight">\(+ \theta_4 x_{n}^4\)</span>) to model an order 4 polynomial and so on.</p>
<p>Execute the next cell to generate and plot the data we will fit.</p>
<p>Execute this cell to simulate some data</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>#@markdown Execute this cell to simulate some data

### Generate training data
np.random.seed(0)
n_train_samples = 50
x_train = np.random.uniform(-2, 2.5, n_train_samples) # sample from a uniform distribution over [-2, 2.5)
noise = np.random.randn(n_train_samples) # sample from a standard normal distribution
y_train =  x_train**2 - x_train - 2 + noise

### Generate testing data
n_test_samples = 20
x_test = np.random.uniform(-3, 3, n_test_samples) # sample from a uniform distribution over [-2, 2.5)
noise = np.random.randn(n_test_samples) # sample from a standard normal distribution
y_test =  x_test**2 - x_test - 2 + noise

## Plot both train and test data
fig, ax = plt.subplots()
plt.title(&#39;Data&#39;)
plt.plot(x_train, y_train, &#39;.&#39;, markersize=15, label=&#39;Training&#39;)
#plt.plot(x_test, y_test, &#39;g+&#39;, markersize=15, label=&#39;Test&#39;)
#plt.legend()
plt.xlabel(&#39;x&#39;)
plt.ylabel(&#39;y&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Week10Tutorial1_10_0.png" src="../_images/Week10Tutorial1_10_0.png" />
</div>
</div>
<section id="a-structuring-the-design-matrix">
<h2>A) Structuring the design matrix<a class="headerlink" href="#a-structuring-the-design-matrix" title="Permalink to this headline">#</a></h2>
<p>For linear regression, we used <span class="math notranslate nohighlight">\(X = x\)</span> as our design matrix. To add a constant bias (a y-intercept in a 2-D plot), we use <span class="math notranslate nohighlight">\(X = \big[ \boldsymbol 1, x \big]\)</span>, where <span class="math notranslate nohighlight">\(\boldsymbol 1\)</span> is a column of ones.  When fitting, we learn a weight for each column of this matrix. So we learn a weight that multiples with column 1 - in this case that column is all ones so we gain the bias parameter (<span class="math notranslate nohighlight">\(+ \theta_0\)</span>). We also learn a weight for every column, or every feature of x.</p>
<p>The key difference between fitting a linear regression model and a polynomial regression model lies in how we create the design matrix. How should we construct the design matrix <span class="math notranslate nohighlight">\(X\)</span> so that a 3rd order polynomial regression model can be in matrix form as <span class="math notranslate nohighlight">\(Y = X\theta\)</span>? What is <span class="math notranslate nohighlight">\(\theta\)</span>?  Write out the matrix multiplication for a row of <span class="math notranslate nohighlight">\(Y\)</span> to show it works out equal.</p>
<section id="answer">
<h3>Answer<a class="headerlink" href="#answer" title="Permalink to this headline">#</a></h3>
<p><font color='green'><span style="font-size:larger;">
Answer here</p>
</section>
</section>
<section id="b-coding-the-design-matrix">
<h2>B) Coding the design matrix<a class="headerlink" href="#b-coding-the-design-matrix" title="Permalink to this headline">#</a></h2>
<p>Complete the function below(<code class="docutils literal notranslate"><span class="pre">make_design_matrix</span></code>) to structure the design matrix given the input data and the order of the polynomial you wish to fit.</p>
<section id="id1">
<h3>Answer<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p><font color='green'><span style="font-size:larger;">
Complete code below</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def make_design_matrix(x, order):
  &quot;&quot;&quot;Create the design matrix of inputs for use in polynomial regression

  Args:
    x (ndarray): input vector of shape (n_samples)
    order (scalar): polynomial regression order

  Returns:
    ndarray: design matrix for polynomial regression of shape (samples, order+1)
  &quot;&quot;&quot;

  # Broadcast to shape (n x 1) so dimensions work
  if x.ndim == 1:
    x = x[:, None]

  #if x has more than one feature, we don&#39;t want multiple columns of ones so we assign
  # x^0 here
  design_matrix = np.ones((x.shape[0], 1))

  # Finish creating the design matrix (hint: np.hstack)
  for degree in range(1, order + 1):
      design_matrix = ...

  return design_matrix


order = 5
X_design = make_design_matrix(x_train, order)
print(X_design[0:2, 0:2])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">line</span> <span class="mi">29</span>
<span class="g g-Whitespace">     </span><span class="mi">27</span> <span class="n">order</span> <span class="o">=</span> <span class="mi">5</span>
<span class="g g-Whitespace">     </span><span class="mi">28</span> <span class="n">X_design</span> <span class="o">=</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">29</span> <span class="nb">print</span><span class="p">(</span><span class="n">X_design</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>

<span class="ne">TypeError</span>: &#39;ellipsis&#39; object is not subscriptable
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="fitting-polynomial-regression-models">
<h2>Fitting polynomial regression models<a class="headerlink" href="#fitting-polynomial-regression-models" title="Permalink to this headline">#</a></h2>
<p>We will use this design matrix function to fit polynomial regression models of different orders. We are doing this using the same function we completed in Week 9 Tutorial 1 (<code class="docutils literal notranslate"><span class="pre">ordinary_least_squares</span></code>). I provide you with the code below but just make sure you understand what is happening.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def solve_poly_reg(x, y, order):
  &quot;&quot;&quot;Fit a polynomial regression model for a given order.

  Args:
    x (ndarray): input vector of shape (n_samples)
    y (ndarray): vector of measurements of shape (n_samples)
    order (scalar): order of polynomial fit

  Returns:
    ndarray: fitted weights of polynomial model
  &quot;&quot;&quot;

  # Create design matrix
  X_design = make_design_matrix(x, order)

  # Fit polynomial model (use ordinary_least_squares)
  theta_hat = ordinary_least_squares(X_design, y)

  return theta_hat


# Loop over several orders and fit polynomial regressions
max_order = 5
theta_hats = {}
for order in range(max_order + 1):
  theta_hats[order] = solve_poly_reg(x_train, y_train, order)

plot_fitted_polynomials(x_train, y_train, theta_hats)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AttributeError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">line</span> <span class="mi">26</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span> <span class="n">theta_hats</span> <span class="o">=</span> <span class="p">{}</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span> <span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">26</span>   <span class="n">theta_hats</span><span class="p">[</span><span class="n">order</span><span class="p">]</span> <span class="o">=</span> <span class="n">solve_poly_reg</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">28</span> <span class="n">plot_fitted_polynomials</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">theta_hats</span><span class="p">)</span>

<span class="nn">Cell In[6], line 17,</span> in <span class="ni">solve_poly_reg</span><span class="nt">(x, y, order)</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="n">X_design</span> <span class="o">=</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="c1"># Fit polynomial model (use ordinary_least_squares)</span>
<span class="ne">---&gt; </span><span class="mi">17</span> <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">ordinary_least_squares</span><span class="p">(</span><span class="n">X_design</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="k">return</span> <span class="n">theta_hat</span>

<span class="nn">Cell In[3], line 15,</span> in <span class="ni">ordinary_least_squares</span><span class="nt">(X, y)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="sd">&quot;&quot;&quot;Ordinary least squares estimator for linear regression.</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span><span class="sd"> </span>
<span class="g g-Whitespace">      </span><span class="mi">6</span><span class="sd"> Args:</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span><span class="sd">   ndarray: estimated parameter values of shape (n_regressors)</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span><span class="sd"> &quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="c1"># Compute theta_hat using OLS</span>
<span class="ne">---&gt; </span><span class="mi">15</span> <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="k">return</span> <span class="n">theta_hat</span>

<span class="ne">AttributeError</span>: &#39;ellipsis&#39; object has no attribute &#39;T&#39;
</pre></div>
</div>
</div>
</div>
<p><strong>In this exercise, we saw we could create a polynomial regression model by using the linear regression setup and altering the design matrix. Altering the design matrix and using linear regression is a powerful tool! For example, in neuroscience, we might want to fit temporal lags (so recent history of a stimulus, not just the current frame). We can create the design matrix in such a way as to include the temporal lags</strong></p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-2-bias-variance-tradeoff">
<h1>Exercise 2: Bias variance tradeoff<a class="headerlink" href="#exercise-2-bias-variance-tradeoff" title="Permalink to this headline">#</a></h1>
<section id="a-thinking-about-models">
<h2>A) Thinking about models<a class="headerlink" href="#a-thinking-about-models" title="Permalink to this headline">#</a></h2>
<p><strong>Answer these before moving on</strong></p>
<p>These questions relate to the models we’ve just fit in Exercise 1:</p>
<p>i) Which model do you think will have the lowest training MSE (mean squared error on the data with which the models are fit)? Why?</p>
<p>ii) Which model do you think could have lowest test MSE? Why? (we’ll accept several answers as long as the reasoning is good since it’s hard to tell from the plot)</p>
<p>iii) Which model has lowest variance (and highest bias)? Why?</p>
<p>iv) Which model has high variance and low bias? Why?</p>
<p><strong>Now look at the next sections to validate your answers.</strong></p>
<section id="id2">
<h3>Answer<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<p><font color='green'><span style="font-size:larger;">
Answer here</p>
</section>
</section>
<section id="looking-at-bias-vs-variance">
<h2>Looking at bias vs variance<a class="headerlink" href="#looking-at-bias-vs-variance" title="Permalink to this headline">#</a></h2>
<p>In the plots below, I have resampled new data sets (new samples) from the true data distribution. I have fit each polynomial order to each new sample. Note that we cannot usually resample data from the actual distribution - we would normally use bootstrapping!</p>
<p>I am plotting the true data model in black and each fit model in green.</p>
<p>Execute to visualize multiple fits</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute to visualize multiple fits
np.random.seed(121)

fig, axes = plt.subplots(1, 6, figsize = (15, 4), sharey=True)


x_grid = np.linspace(x_train.min() - .5, x_train.max() + .5)
X_design = {}
y_hats = {}
for order in range(max_order + 1):
  X_design[order] = make_design_matrix(x_grid, order)
  y_hats[order] = np.zeros((0, len(x_grid)))

for i_sample in range(30):

  # Sample new data
  n_samples = 30
  x = np.random.uniform(-2, 2.5, n_samples)  # inputs uniformly sampled from [-2, 2.5)
  y =  x**2 - x - 2   # computing the outputs

  output_noise = 1.5 * np.random.randn(n_samples)
  y += output_noise  # adding some output noise

  # Loop over several orders and fit polynomial regressions
  max_order = 5
  theta_hats = {}
  for order in range(max_order + 1):
    theta_hats[order] = solve_poly_reg(x, y, order)

    y_hat = X_design[order] @ theta_hats[order]
    y_hats[order] = np.concatenate((y_hats[order], y_hat[None, :]), axis=0)
    axes[order].plot(x_grid, y_hat, &#39;g&#39;, alpha=.2, label=&#39;Fitted models&#39; if i_sample == 0 else &quot;&quot;)

for order in range(max_order + 1):
  axes[order].plot(x_grid, X_design[2] @ np.array([-2, -1, 1]), &#39;k&#39;, label=&#39;True model&#39;)
  axes[order].set(ylim=[-15, 15], xlabel=&#39;x&#39;, ylabel=&#39;y&#39;, title=&#39;Order &#39;+str(order))

leg = axes[0].legend(loc=&#39;best&#39;, frameon=False, handlelength=0)
# change the font colors to match the line colors:
for line,text in zip(leg.get_lines(), leg.get_texts()):
    text.set_color(line.get_color())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AttributeError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">line</span> <span class="mi">28</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span> <span class="n">theta_hats</span> <span class="o">=</span> <span class="p">{}</span>
<span class="g g-Whitespace">     </span><span class="mi">27</span> <span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">28</span>   <span class="n">theta_hats</span><span class="p">[</span><span class="n">order</span><span class="p">]</span> <span class="o">=</span> <span class="n">solve_poly_reg</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">30</span>   <span class="n">y_hat</span> <span class="o">=</span> <span class="n">X_design</span><span class="p">[</span><span class="n">order</span><span class="p">]</span> <span class="o">@</span> <span class="n">theta_hats</span><span class="p">[</span><span class="n">order</span><span class="p">]</span>
<span class="g g-Whitespace">     </span><span class="mi">31</span>   <span class="n">y_hats</span><span class="p">[</span><span class="n">order</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">y_hats</span><span class="p">[</span><span class="n">order</span><span class="p">],</span> <span class="n">y_hat</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nn">Cell In[6], line 17,</span> in <span class="ni">solve_poly_reg</span><span class="nt">(x, y, order)</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="n">X_design</span> <span class="o">=</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="c1"># Fit polynomial model (use ordinary_least_squares)</span>
<span class="ne">---&gt; </span><span class="mi">17</span> <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">ordinary_least_squares</span><span class="p">(</span><span class="n">X_design</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="k">return</span> <span class="n">theta_hat</span>

<span class="nn">Cell In[3], line 15,</span> in <span class="ni">ordinary_least_squares</span><span class="nt">(X, y)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="sd">&quot;&quot;&quot;Ordinary least squares estimator for linear regression.</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span><span class="sd"> </span>
<span class="g g-Whitespace">      </span><span class="mi">6</span><span class="sd"> Args:</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span><span class="sd">   ndarray: estimated parameter values of shape (n_regressors)</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span><span class="sd"> &quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="c1"># Compute theta_hat using OLS</span>
<span class="ne">---&gt; </span><span class="mi">15</span> <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="k">return</span> <span class="n">theta_hat</span>

<span class="ne">AttributeError</span>: &#39;ellipsis&#39; object has no attribute &#39;T&#39;
</pre></div>
</div>
<img alt="../_images/Week10Tutorial1_24_1.png" src="../_images/Week10Tutorial1_24_1.png" />
</div>
</div>
<p>We can see that the order 5 model fits vary a lot based on the sample of data used - there is a lot of <strong>variance</strong> over different data samples. On average though, these fits resemble the true model (if you average over the green lines, it is roughly the black line) so this model has low <strong>bias</strong>. The order 0 model has high bias since the predictions do not match the true model on average (but lower variance than the order 5 model). By eye, the order 2 model looks about right as a balance between these tendencies.</p>
</section>
<section id="looking-at-train-vs-test-mse">
<h2>Looking at train vs test MSE<a class="headerlink" href="#looking-at-train-vs-test-mse" title="Permalink to this headline">#</a></h2>
<p>We can compute the mean squared error of each polynomial model on the data it is fit with (the training data) and held-out data (the test data). <strong>No need to answer this explicitly here but discuss how the training MSE should change over order and how the test MSE should before seeing the plot.</strong></p>
<p>Execute to see train and test data</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute to see train and test data
## Plot both train and test data
fig, ax = plt.subplots()
plt.title(&#39;Training &amp; Test Data&#39;)
plt.plot(x_train, y_train, &#39;.&#39;, markersize=15, label=&#39;Training&#39;)
plt.plot(x_test, y_test, &#39;g+&#39;, markersize=15, label=&#39;Test&#39;)
plt.legend()
plt.xlabel(&#39;x&#39;)
plt.ylabel(&#39;y&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Week10Tutorial1_28_0.png" src="../_images/Week10Tutorial1_28_0.png" />
</div>
</div>
<p>Execute to see train vs test MSE</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># @markdown Execute to see train vs test MSE
mse_train = np.zeros((max_order+1))
mse_test = np.zeros((max_order+1))
for order in range(max_order + 1):
  theta_hat = solve_poly_reg(x_train, y_train, order)
  mse_train[order] = evaluate_poly_reg(x_train, y_train, theta_hat, order)
  mse_test[order] = evaluate_poly_reg(x_test, y_test, theta_hat, order)

fig, ax = plt.subplots()
width = .35

ax.bar(np.arange(max_order + 1) - width / 2, mse_train, width, label=&quot;train MSE&quot;)
ax.bar(np.arange(max_order + 1) + width / 2, mse_test , width, label=&quot;test MSE&quot;)

ax.legend()
ax.set(xlabel=&#39;Polynomial order&#39;, ylabel=&#39;MSE&#39;, title =&#39;Comparing polynomial fits&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AttributeError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">9</span><span class="p">],</span> <span class="n">line</span> <span class="mi">5</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">mse_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">max_order</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
<span class="ne">----&gt; </span><span class="mi">5</span>   <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">solve_poly_reg</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span>   <span class="n">mse_train</span><span class="p">[</span><span class="n">order</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluate_poly_reg</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>   <span class="n">mse_test</span><span class="p">[</span><span class="n">order</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluate_poly_reg</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>

<span class="nn">Cell In[6], line 17,</span> in <span class="ni">solve_poly_reg</span><span class="nt">(x, y, order)</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="n">X_design</span> <span class="o">=</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="c1"># Fit polynomial model (use ordinary_least_squares)</span>
<span class="ne">---&gt; </span><span class="mi">17</span> <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">ordinary_least_squares</span><span class="p">(</span><span class="n">X_design</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span> <span class="k">return</span> <span class="n">theta_hat</span>

<span class="nn">Cell In[3], line 15,</span> in <span class="ni">ordinary_least_squares</span><span class="nt">(X, y)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="sd">&quot;&quot;&quot;Ordinary least squares estimator for linear regression.</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span><span class="sd"> </span>
<span class="g g-Whitespace">      </span><span class="mi">6</span><span class="sd"> Args:</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span><span class="sd">   ndarray: estimated parameter values of shape (n_regressors)</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span><span class="sd"> &quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="c1"># Compute theta_hat using OLS</span>
<span class="ne">---&gt; </span><span class="mi">15</span> <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="k">return</span> <span class="n">theta_hat</span>

<span class="ne">AttributeError</span>: &#39;ellipsis&#39; object has no attribute &#39;T&#39;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-3-model-selection-via-cross-validation">
<h1>Exercise 3: Model selection via cross validation<a class="headerlink" href="#exercise-3-model-selection-via-cross-validation" title="Permalink to this headline">#</a></h1>
<p>In Exercise 2, we sampled multiple times from the actual distribution and looked at the test data to think about best model fits - neither of which we can usually do! Let’s do model selection properly using cross-validation.</p>
<section id="a-by-hand-implementation-on-a-toy-example">
<h2>A) By hand implementation on a toy example<a class="headerlink" href="#a-by-hand-implementation-on-a-toy-example" title="Permalink to this headline">#</a></h2>
<p>We usually use sklearn for cross-validation in python. We will first implement cross-validation for a tiny toy example to make sure we understand the steps.</p>
<p>Let’s say we have:</p>
<div class="math notranslate nohighlight">
\[ x =   \begin{bmatrix}
    5 &amp; 10 &amp; 2 &amp; 3 &amp; 1 &amp; 6
  \end{bmatrix}\]</div>
<div class="math notranslate nohighlight">
\[ y = \begin{bmatrix}
   4 &amp; 3 &amp; 1 &amp; 6 &amp; 3 &amp; 4
  \end{bmatrix}\]</div>
<p>We want to fit the model: $<span class="math notranslate nohighlight">\(y = \theta\)</span><span class="math notranslate nohighlight">\( The least squares solution (see derivation below) is \)</span><span class="math notranslate nohighlight">\(\hat{\theta} = \frac{\sum y_i}{N}\)</span>$</p>
<p>Note that this is a standard baseline model - we are essentially modeling y as the average of y in the training data. This would be like predicting the responses of a neuron by using the mean firing rate.</p>
<p>Use 3 fold cross validation (by hand) and report the validation MSE for this model on this data. You may use code or do this by hand, but don’t use any functions for cross validation. Show your work (i.e. specify how you’re splitting the data, report the validation MSE for every split, etc).</p>
<section id="id3">
<h3>Answer<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h3>
<p><font color='green'><span style="font-size:larger;">
Answer here</p>
<p>We could do the same procedure for <span class="math notranslate nohighlight">\(y = \theta x\)</span> and use the validation MSE to pick which model is better (telling us whether y is at all correlated with x). We won’t though for time!</p>
<p><em>Derivation of least squares solution</em>
$<span class="math notranslate nohighlight">\(\begin{align}
y &amp;= \theta \\
MSE &amp; = \frac{1}{N} \sum_i (y_i - \hat{y}_i)^2 \\
&amp; = \frac{1}{N} \sum_i (y_i - \theta)^2 \\
\frac{dMSE}{d\theta} &amp;= \frac{2}{N} \sum_i (y_i - \theta) \\
&amp;= \sum_i (y_i - \theta)  \\
&amp;= \sum_i y_i - \sum_i \theta  \\
&amp;= \sum_i y_i - N\theta = 0 \\
\hat{\theta} &amp;= \frac{\sum_i y_i}{N}
\end{align}\)</span>$</p>
</section>
</section>
<section id="b-using-sklearn">
<h2>B) Using sklearn<a class="headerlink" href="#b-using-sklearn" title="Permalink to this headline">#</a></h2>
<p>Now we can use sklearn to perform cross-validation and select the our model from the different order polynomial models. Here I just use sklearn to get the train/val splits (using the <code class="docutils literal notranslate"><span class="pre">Kfold</span></code> iterator) and then use our functions above to fit the models. At the end of this tutorial, I show how to do everything (including fitting the models) in sklearn.</p>
<p>Nothing to do here but look at the plot and answer the question - I show you the code in case you want to look through it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.model_selection import KFold

def cross_validate(x_train, y_train, max_order, n_splits):
  &quot;&quot;&quot; Compute MSE for k-fold validation for each order polynomial

  Args:
    x_train (ndarray): training data input vector of shape (n_samples)
    y_train (ndarray): training vector of measurements of shape (n_samples)
    max_order (scalar): max order of polynomial fit
    n_split (scalar): number of folds for k-fold validation

  Return:
    ndarray: MSE over splits for each model order, shape (n_splits, max_order + 1)

  &quot;&quot;&quot;
  # Initialize the split method
  kfold_iterator = KFold(n_splits)

  # Initialize np array mse values for all models for each split
  mse_all = np.zeros((n_splits, max_order + 1))

  for i_split, (train_indices, val_indices) in enumerate(kfold_iterator.split(x_train)):

      # Split up the overall training data into cross-validation training and validation sets
      x_cv_train = x_train[train_indices]
      y_cv_train = y_train[train_indices]
      x_cv_val = x_train[val_indices]
      y_cv_val = y_train[val_indices]

      # Fit and evaluate models
      for order in range(max_order + 1):
          theta_hat = solve_poly_reg(x_cv_train, y_cv_train, order)
          mse_all[i_split, order] = evaluate_poly_reg(x_cv_val, y_cv_val, theta_hat, order)

  return mse_all


# Call function and plot
max_order = 5
n_splits = 10

plt.figure()

mse_all = cross_validate(x_train, y_train, max_order, n_splits)
plt.boxplot(mse_all, labels=np.arange(0, max_order + 1))

plt.xlabel(&#39;Polynomial Order&#39;)
plt.ylabel(&#39;Validation MSE&#39;)
plt.title(f&#39;Validation MSE over {n_splits} splits of the data&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="k">def</span> <span class="nf">cross_validate</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">max_order</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">):</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>   <span class="sd">&quot;&quot;&quot; Compute MSE for k-fold validation for each order polynomial</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span><span class="sd"> </span>
<span class="g g-Whitespace">      </span><span class="mi">6</span><span class="sd">   Args:</span>
<span class="sd">   (...)</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span><span class="sd"> </span>
<span class="g g-Whitespace">     </span><span class="mi">15</span><span class="sd">   &quot;&quot;&quot;</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;sklearn&#39;
</pre></div>
</div>
</div>
</div>
<p>Which polynomial order do you think is a better model of the data based on cross-validation? Why?</p>
<p>Note it may not be what you expected - we’ll discuss in class!</p>
<section id="id4">
<h3>Answer<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h3>
<p><font color='green'><span style="font-size:larger;">
Answer here</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="coding-fun-everything-in-sklearn">
<h1>Coding Fun: Everything in sklearn<a class="headerlink" href="#coding-fun-everything-in-sklearn" title="Permalink to this headline">#</a></h1>
<p>Let’s look at implementing polynomial regression models, fitting them, and performing cross-validation entirely in sklearn.</p>
<p>We create a polynomial regression model by chaining together a preprocessing step that turns the data into polynomial features and a linear regression model. (Note that if we have more than 1D data, this would create interaction terms which we may not want).</p>
<p>See here for more details: https://towardsdatascience.com/polynomial-regression-with-scikit-learn-what-you-should-know-bed9d3296f2</p>
<p>The code below fits an order 3 polynomial regression model, looks at the fitted parameters, and gets predictions/R2 value</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression

# Create polynomial regression model
degree = 3
poly_reg = make_pipeline(PolynomialFeatures(degree),LinearRegression())

# Fit this model to data
poly_reg.fit(x_train[:, None], y_train)

# You can now look at theta_hat
print(poly_reg[&#39;linearregression&#39;].coef_)

# Let&#39;s make predictions on test data
y_hat = poly_reg.predict(x_test[:, None])

# Let&#39;s evaluate on test data (this returns R2)
poly_reg.score(x_test[:, None], y_test)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">11</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;sklearn&#39;
</pre></div>
</div>
</div>
</div>
<p>The code below does cross validation with 10 splits for an order 3 polynomial regression model. We could loop over this to get the validation MSE for each order model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.model_selection import cross_val_score

## Let&#39;s get validation MSE for this model using cross-validation

# Create polynomial regression model
degree = 3
poly_reg = make_pipeline(PolynomialFeatures(degree),LinearRegression())

# Cross-validation
val_mse = cross_val_score(poly_reg, x_train[:, None], y_train, cv = 10, scoring=&#39;neg_mean_squared_error&#39;)

# This has return negative MSE so let&#39;s get actual MSE
val_mse *= -1

print(val_mse)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">12</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="c1">## Let&#39;s get validation MSE for this model using cross-validation</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> 
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># Create polynomial regression model</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">degree</span> <span class="o">=</span> <span class="mi">3</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;sklearn&#39;
</pre></div>
</div>
</div>
</div>
<p>Let’s get really fancy and using <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> to search over all the orders of polynomial regression we’re looking at and perform cross-validation for each.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.model_selection import GridSearchCV

# Parameters we want to search over
parameters = {&#39;polynomialfeatures__degree&#39;: [0, 1, 2, 3, 4, 5]}

# Set up cross validation
poly_reg = make_pipeline(PolynomialFeatures(),LinearRegression())

cv = GridSearchCV(poly_reg, parameters, cv = 10, scoring=&#39;neg_mean_squared_error&#39;)
cv.fit(x_train[:, None], y_train)

plt.plot(np.arange(max_order + 1), -1*cv.cv_results_[&#39;mean_test_score&#39;], &#39;-og&#39;)
plt.xlabel(&#39;Order&#39;)
plt.ylabel(&#39;Validation MSE&#39;);
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">13</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="c1"># Parameters we want to search over</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;polynomialfeatures__degree&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]}</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;sklearn&#39;
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "ebatty/MathToolsforNeuroscience",
            ref: "jupyterbook",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Week10"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Video103.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Video 10.3: Model selection</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Week10Tutorial2.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Tutorial 2</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ella Batty<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>